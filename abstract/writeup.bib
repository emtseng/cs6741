@inproceedings{serban2016building,
  title={Building end-to-end dialogue systems using generative hierarchical neural network models},
  author={Serban, Iulian V and Sordoni, Alessandro and Bengio, Yoshua and Courville, Aaron and Pineau, Joelle},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@InProceedings{Chang-Trouble:19,
  author={Chang, Jonathan P and Danescu-Niculescu-Mizil, Cristian},
  title={Trouble on the Horizon: Forecasting the Derailment of Online Conversations as they Develop},
  booktitle={Proceedings of EMNLP},
  year={2019},
}

@misc{convokit,
  author={Chang, Jonathan P and Chiam, Caleb and Fu, Liye and Wang, Andrew and Zhang, Justine and Danescu-Niculescu-Mizil, Cristian},
  year={2019},
  title={ConvoKit: The Cornell Conversational Analysis Toolkit},
  note={Retrieved from http://convokit.cornell.edu},
}

@article{clark2019does,
  title={What Does BERT Look At? An Analysis of BERT's Attention},
  author={Clark, Kevin and Khandelwal, Urvashi and Levy, Omer and Manning, Christopher D},
  journal={arXiv preprint arXiv:1906.04341},
  year={2019}
}

@InProceedings{esmaeili19,
  title = 	 {Structured Neural Topic Models for Reviews},
  author = 	 {Esmaeili, Babak and Huang, Hongyi and Wallace, Byron and Meent, Jan-Willem van de},
  booktitle = 	 {Proceedings of Machine Learning Research},
  pages = 	 {3429--3439},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {16--18 Apr},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v89/esmaeili19b/esmaeili19b.pdf},
  url = 	 {http://proceedings.mlr.press/v89/esmaeili19b.html},
  abstract = 	 {We present Variational Aspect-based Latent Topic Allocation (VALTA), a family of autoencoding topic models that learn aspect-based representations of reviews. VALTA defines a user-item encoder that maps bag-of-words vectors for combined reviews associated with each paired user and item onto structured embeddings, which in turn define per-aspect topic weights. We model individual reviews in a structured manner by inferring an aspect assignment for each sentence in a given review, where the per-aspect topic weights obtained by the user-item encoder serve to define a mixture over topics, conditioned on the aspect. The result is an autoencoding neural topic model for reviews, which can be trained in a fully unsupervised manner to learn topics that are structured into aspects. Experimental evaluation on large number of datasets demonstrates that aspects are interpretable, yield higher coherence scores than non-structured autoencoding topic model variants, and can be utilized to perform aspect-based comparison and genre discovery.}
}
