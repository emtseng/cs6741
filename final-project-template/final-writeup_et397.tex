\documentclass{article}

\usepackage{times}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{subfigure}
\usepackage{natbib}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amssymb}
\usepackage{lipsum}
\usepackage{todonotes}

\def\authnotes{1}

\newcounter{notectr}[section]
\newcommand{\thenote}{\thesubsection.\arabic{notectr}\refstepcounter{notectr}}

\newcommand{\fixme}[1]{\textcolor{red}{[FIXME: #1]}}
\newcommand{\note}[2]{$\ll$#1~\thenote: #2$\gg$}
\newcommand{\enote}[1]{\ifnum\authnotes=1 \textcolor{blue}{\note{EmilyT}{#1}}\fi}


\usepackage[accepted]{icml2017}
\icmltitlerunning{CS 287 Final Project Template}

\begin{document}

\twocolumn[
\icmltitle{Generative Pretraining for Supervised Analysis of Therapeutic Alliance in Online Therapy Conversations}
\begin{icmlauthorlist}
  \icmlauthor{Emily Tseng}{}
\end{icmlauthorlist}

\vskip 0.3in
]

\begin{abstract}
  \begin{itemize}
  \item This document describes the expected style, structure, and rough proportions for your final project write-up.
  \item While you are free to break from this structure, consider it a strong prior for our expectations of the final report.
  \item Length is a hard constraint. You are only allowed max \textbf{8 pages} in this format. While you can include supplementary material, it will not be factored into the grading process. It is your responsibility to convey the main contributions of the work in the length given.
  \end{itemize}


\end{abstract}

\section{Introduction}
\label{sec:introduction}

Example Structure:
\begin{itemize}
\item What is the problem of interest and what (high-level) are the current best methods for solving it?
\item How do you plan to improve/understand/modify this or related methods?
\item Preview your research process, list the contributions you made, and summarize your experimental findings.
\end{itemize}



In therapeutic and caregiving contexts, a patient’s felt sense of \textit{alliance} with a care provider can make or break their treatment. This is particularly important in remote caregiving contexts like online therapy, where the vast majority of the connection between the patient and the caregiver takes place entirely over text-chat. 

% Yet, to-date there have been few attempts to develop rigorous ways to measure how alliance manifests over a remote caregiving connection. What conversational cues or strategies, delivered over what modalities, best create a sense of alliance? How long does it take to build alliance, and how quickly can it dissolve? How is alliance re-established? How does alliance intersect with a patient’s sense of therapist fit, and what is the impact of switching therapists on a patient’s future alliance development?

In this work, we provide a proof of concept for the use of neural representations of high-level conversational dynamics in forecasting alliance between patients and therapists. We describe a model for predicting alliance at any given point in a conversation, and examine its potential using a proprietary dataset of text-chat therapy transcripts and patient-provided alliance scores from a major provider of online therapy services. \fixme{We compare the performance of our conversational dynamics embeddings against a traditional feature-engineered method. (CBOW)} Our contributions are as follows:

\begin{itemize}
  \item Contribution 1
\end{itemize}

\section{Background}
\label{sec:background}

\fixme{What are the challenges/opportunities inherent to the data? (High dimensional, sparse, missing data, noise, structure, discrete/continuous, etc?)}
% Example Structure:
% \begin{itemize}
% \item What information does a non-expert need to know about the problem domain?
% \item What data exists for this problem?
% \item What are the challenges/opportunities inherent to the data? (High dimensional, sparse, missing data, noise, structure, discrete/continuous, etc?)
% \end{itemize}

\textbf{Therapeutic alliance and WAI.} The psychology literature has had a longstanding interest in the role of the relationship between the therapist and the patient in successful psychotherapy. Early works posited that a beneficial attachment between patient and therapist enables the patient to trust the therapist enough to use his or her interpretations to bring about positive change (for a review, see Ardito \& Rabellino \citeyear{ardito2011therapeutic}). Bordin \citeyear{bordin1979generalizability} defined the concept of a \textit{working alliance} as the relational underpinning of many approaches to psychotherapy, and outlined that different types of alliance emerge from different approaches. Regardless of approach, Bordin argues, it is the \textit{strength} of the alliance that best predicts positive outcomes.

As a way to measure alliance in a given patient-therapist relationship, Horvath \& Greenberg \citeyear{horvath1989development} proposed the Working Alliance Inventory (WAI), a set of self-reported scales that measure the quality of the alliance along the three dimensions defined in Bordin's theoretical framework: (1) the \textit{bond} between patient and therapist, (2) the agreement on the \textit{goals} of the therapy, and (3) the agreement on the \textit{tasks} required to achieve those goals. Available in variants from the perspective of the patient, the therapist, and a third-party observer, the WAI has been validated as a reliable metric for alliance in several contexts (for a meta-analysis, see Martin et al. \citeyear{martin2000relation}).

\textbf{Online therapy.}


\section{Related Work}
\label{sec:related-work}

Example Structure:
\begin{itemize}
\item What 3-5 papers have been published in this space?
\item How do these differ from your approach?
\item What data or methodologies do each of these works use?
\item How do you plan to compare to these methods?
\end{itemize}

\textbf{NLP and therapy.} \fixme{cite Althoff work, etc}

\textbf{Conversational forecasting.} Methodologically, our work is an adaptation of the Conversational Recurrent Architecture for ForecasTing (CRAFT), a framework integrating generative pre-training with a supervised fine-tuning model to achieve improved predictive ability on conversation-level attributes, e.g., whether an online conversation will derail into personal attacks \cite{Chang-Trouble:19}. Whereas CRAFT focused on prediction of a binary outcome (derailment vs. non-derailment) in public-facing conversations on Reddit and Wikipedia, our work focuses on classification of segments of a conversation into one of multiple outcomes (buckets of WAI scores, as described in section \ref{sec:dataset}).

\section{Dataset}
\label{sec:dataset}

We consider a dataset of therapy transcripts and associated patient outcomes from Talkspace, an online therapy platform. Due to the highly sensitive nature of therapy, we put significant effort into respecting patients' privacy and autonomy. All represented patients gave informed consent for the use of their data in research, and transcripts were anonymized by Talkspace before they were handed to our research team. Our study protocol was approved by our institutional IRB.

In total, our dataset consists of 5.7M messages exchanged between patients and therapists, representing 11,233 patients' full courses of treatment. 1,906 therapists are represented, with an average of 9 patients per therapist. 

Outcome annotations are provided in the form of patients' responses to surveys issued approximately every 3 weeks. In total, 13,742 WAI scores were provided by 6,702 patients. Patients provided an average of 2.1 WAI scores (range 1-24, stdev 2.2). As depicted in Figure \ref{fig:wai-distribution}, The overall distribution of scores skewed strongly towards the positive end of the spectrum (more strongly allied). Given this, in this project we formulated our predictive task as multiclass classification between three buckets of scores: 0-14, 15-19, and 20.

\begin{figure}
  \includegraphics[width=\columnwidth]{figs/wai-distribution.png}
  \caption{Distribution of WAI scores across Goal, Task and Bond dimensions.}
  \label{fig:wai-distribution}
\end{figure}


\section{Model}
\label{sec:model}

% \item What is the formal definition of your problem?
% \item What is the precise mathematical model you are using to represent it? In almost all cases this will use the probabilistic language from class, e.g.
%   \begin{equation}
%   z \sim {\cal N}(0, \sigma^2)\label{eq:1}
% \end{equation}
% But it may also be a neural network, or a non-probabilistic loss,
% \[ h_t \gets \mathrm{RNN}(x_{t}, h_{t-1} )\]

% This is also a good place to reference a diagram such as Figure~\ref{fig:diagram}.


% \begin{figure}
%   \centering
%   \missingfigure[figheight=8cm]{}
%   \caption{\label{fig:diagram} This is a good place to include a diagram showing how your model works. Examples include a graphical model or a neural network block diagram.}
% \end{figure}

Our model is an adaptation of the Conversational Recurrent Architecture for ForecasTing (CRAFT) \cite{Chang-Trouble:19}, which integrates a generative dialogue model and a supervised fine-tuning component to produce predictions utterance-by-utterance about some high-level conversational state (in their work, whether an online exchange will derail).

\textbf{Problem definition.} We define a conversation $C$ as a variable-length sequence of $n$ utterances, $C=\{u_1,...,u_n\}$. Utterances are variable-length sequences of tokens $w$, and thus $u_n=\{w_1,...,w_{M_n}\}$, where $M_n$ is the length in tokens of utterance $n$.

Given a therapy exchange $C=\{u_1,...,u_n\}$, we generate $h^{con}_n$, a neural representation of high-level conversational state up to utterance $u_n$. We then use $h^{con}_n$ as the input to a classifier that predicts $y_n$, the label attached to the conversation up to utterance $n$. We define the label $y_n$ based on the WAI score provided by the patient at utterance $u_n$: 0 if the score is in the bucket 0-14, 1 if 15-19, and 2 if the score is 20.

\textbf{Generative component.} Following Chang et al. \citeyear{Chang-Trouble:19}, we adopted for our generative component the hierarchical recurrent encoder-decoder (HRED) architecture proposed in Sordoni et al. \citeyear{sordoni2015hierarchical} and Serban et al. \citeyear{serban2016building}. Built to model high-level conversational context, including temporal structure and dependencies between consecutive sequential inputs, HREDs are uniquely suited for conversational forecasting tasks. 

HREDs are comprised of three component recurrent neural networks (RNNs): an utterance encoder, a conversation encoder, and a decoder. First, the \textit{utterance encoder} generates for each utterance a semantic vector representation via its hidden state $h^{enc} \in \mathbb{R}^d_{enc}$, where $d_{enc}$ is the desired dimension. For each token $w_m$ in utterance $n$ of length $M$, the encoder updates its $h^{enc}$ like so:
\begin{equation}
  h^{enc}_m \gets f^{RNN}(w_{m}, h^{enc}_{m-1})
\end{equation}
The utterance encoder's hidden state at the last step, $h^{enc}_{M}$, in theory represents an embedding for the entire utterance. Following Serban et al. \citeyear{serban2016building}, $h^{enc}_{0}$ is initialized as the zero vector $\mathbf{0}$, and following Chang et al. \citeyear{Chang-Trouble:19}, we use the GRU \cite{cho2014learning} as our nonlinear gating function $f^{RNN}$.

Next, the \textit{conversation encoder} uses the hidden states from each consecutive comment in a sequence of length $N$ to produce an embedding $h^{con}_n$ for the conversation up to the utterance at that point ($u_N$):
\begin{equation}
  h^{con}_n \gets f^{RNN}(h^{enc}_{M_n}, h^{con}_{n-1})
\end{equation}
The conversation encoder also initializes its hidden state $h^{con}_0$ with the zero vector $\mathbf{0}$, and also uses the GRU as its nonlinearity. We denote the dimension of $h^{con}$ as $d_{con}$.

The \textit{decoder} uses the embedded conversational context $h^{con}_n$ to generate a response to utterance $n$. Following Sordoni et al. \citeyear{sordoni2015hierarchical}, it does this by first initializing its own hidden state $h^{dec} \in \mathbb{R}^{d_{dec}}$ using a nonlinear activation of $h^{con}_n$:
\begin{equation}
  h^{dec}_0 = \tanh(D h^{con}_n + b_0)
\end{equation}
Where $D \in \mathbb{R}^{d_{dec} \times d_{con}}$ projects the context embedding into decoder space, and $b_0 \in \mathbb{R}^{d_{dec}}$. 
The decoder then updates its own hidden state for each response token using the following recurrence:
\begin{equation}
  h^{dec}_{t} \gets f^{RNN}(w_{t-1}, h^{dec}_{t-1})
\end{equation}
The decoder then produces the next token in its response by producing a probability distribution over words from $h^{dec}_t$:
\begin{equation}
  w_t = f^{out}(h^{dec}_t)
\end{equation}

\fixme{at generation...}

\textbf{Predictive component.} Our predictive component uses the conversational embedding up to utterance $u_n$ to generate a prediction for the WAI score at that utterance. We operationalize this as a multi-layer perceptron (MLP) that takes in the conversational state $h^{con}_n$ and produces a distribution $p(Y_n|h^{con}_n)$ over possible labels $Y=\{0,1,2\}$. Adapting from Chang et al. (\citeyear{Chang-Trouble:19}), our MLP uses three fully-connected layers and leaky ReLU activations between each layer; but for our task of multilabel classification, we use a softmax activation. The result is a model that creates a probability distribution in which each score can be interpreted as the likelihood of the given label.

\textbf{Parameters.} \fixme{What are the parameters or latent variables of this model that you plan on estimating or inferring? Be explicit. How many are there? Which are you assuming are given? How do these relate to the original problem description?}



\section{Training}
\label{sec:training}

\fixme{todo: lift from Chang}

\begin{itemize}
\item How do you plan on training your parameters / inferring the
  states of your latent variables (MLE / MAP / Backprop / VI / EM / BP / ...)

\item What are the assumptions implicit in this technique? Is it an approximation or exact? If it is an approximation what bound does it optimize?

\item What is the explicit method / algorithm that you derive for learning these parameters?
\end{itemize}


% \begin{algorithm}
%   \begin{algorithmic}
%     \STATE{\lipsum[1]}
%   \end{algorithmic}
%   \caption{Your Pseudocode}
% \end{algorithm}




\section{Methods}
\label{sec:methods}

\fixme{For each section: What are the exact details of the dataset that you used? (Number of data points / standard or non-standard / synthetic or real / exact form of the data)
}

\fixme{
How did you train or run inference? (Optimization method / hyperparameter settings / amount of time ran / what did you implement versus borrow / how were baselines computed).
}

\fixme{What are the exact details of the metric used?}

\textbf{Generative pre-training.} We began by training our generative model following the structure outlined in section \ref{sec:training}. From our dataset of 5.7M messages we randomly subsampled 250k pairs of contexts (sequences of utterances) and replies. Randomization allowed our model to see a variety of contexts from a variety of conversations, as opposed to repeatedly seeing subsets of the same conversations. For example, in context-reply pairs $(\{u_1,...,u_{n-1}\}, u_{n})$ and $(\{u_1,...,u_{n}\}, u_{n+1})$ from the same conversation, the subsequence of utterances $\{u_1,...,u_{n-1}\}$ repeat across both contexts.

Our generative model was implemented using Pytorch \cite{paszke2019pytorch}, and optimized using that framework's built-in Adam optimizer. Encoder and conversation encoder learning rates were set at 0.0001, and the decoder learning rate was set at 0.005.

\textbf{Fine-tuning the predictive component.} All experiments with the predictive component of CRAFT-Multilabel initialized training with encoder, conversation encoder, and decoder parameters from the final generative model.  

\textbf{BoW comparison.} Core to the proposed applicability of the CRAFT-Multilabel framework is its ability to represent the high-level conversational dynamics that emerge from utterances in sequence (e.g., derailment, the level of working alliance present), and make predictions about those high-level conversational dynamics by using those representations as features in a downstream task. 

To test whether our model was indeed representing higher-level semantics, we compared CRAFT-Multilabel against a simple bag-of-words (BoW) model. Given a vocabulary $V$, BoW represents an input context as a $|V|$-length vector of the counts of each word in $V$ in the context. In our implementation, we normalized the raw counts of each word in $V$ according to their relative importance within their contexts, quantified by their term frequency-inverse document frequency (tf-idf). This $|V|$-length feature vector $x$ is then used as the input to a simple feedforward MLP that mimics the structure of the predictive component of CRAFT-Multilabel: that is, it produces a distribution $p(Y|x)$ over possible labels $Y=\{0,1,2\}$.

Note that the BoW by definition only captures relative word occurrences; it does not capture word order, or even boundaries between the utterances in our contexts, to say nothing of higher-level conversational dynamics. Thus, comparison of BoW against CRAFT-Multilabel should demonstrate the effect of incorporating such conversation-level attributes into this predictive task.

Our BoW was an MLP trained via scikit-learn's Adam optimizer \cite{scikit-learn} for 200 iterations with a constant learning rate of 0.001. Similar to the predictive component of CRAFT-Multilabel, the MLP consisted of 2 hidden layers of size 100, each of which used a ReLU activation.

\textbf{Data.} For this proof of concept we compared 


\section{Results}
\label{sec:results}

\begin{table}[t]
  \centering
  \begin{tabular}{@{}cc@{}}
  \toprule
  \textbf{Model}            & \textbf{Validation-set Accuracy} \\ \midrule
  Random guessing           & 0.3333                           \\
  BoW                       & 0.5577                           \\
  \textbf{CRAFT-Multilabel} & \textbf{0.6375}                  \\ \bottomrule
  \end{tabular}
  \caption{Performance of the BoW vs. CRAFT-Multilabel models. All trials run with a validation subset of 159 context/label pairs evenly balanced between the 3 classes. The random baseline (a model that only outputs 1 class) is shown for comparison.}
  \label{tab:results}
\end{table}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\columnwidth]{figs/cm-bow.png}
  \includegraphics[width=0.9\columnwidth]{figs/cm-craftmulti.png}
  \caption{Confusion matrices for the BoW vs. CRAFT-Multilabel models.}
  \label{fig:confusion-matrices}
\end{figure}

\begin{itemize}
\item What were the results comparing previous work / baseline systems / your systems on the main task?
\item What were the secondary results comparing the variants of your system?
\item This section should be fact based and relatively dry. What happened, what was significant?
\end{itemize}

% \begin{table*}
%   \centering
%   \missingfigure{}
%   \caption{This is usually a table. Tables with numbers are generally easier to read than graphs, so prefer when possible.}
%   \label{fig:mainres}
% \end{table*}


% \begin{table}
%   \centering
%   \missingfigure[figheight=5cm]{}
%   \caption{Secondary table or figure in results section.}
%   \label{fig:mainres}
% \end{table}


\section{Discussion}
\label{sec:discussion}

\begin{itemize}
\item What conclusions can you draw from the results section?
\item Is there further analysis you can do into the results of the system? Here is a good place to include visualizations, graphs, qualitative analysis of your results.

\item What questions remain open? What did you think might work, but did not?
\end{itemize}


% \begin{figure}
%   \centering
%   \missingfigure{}
%   \missingfigure{}
%   \missingfigure{}
%   \caption{Visualizations of the internals of the system.}
% \end{figure}

\section{Conclusion}

\begin{itemize}
\item What happened?
\item What next?
\end{itemize}


% \section*{Acknowledgements}

% \textbf{Do not} include acknowledgements in the initial version of
% the paper submitted for blind review.

% If a paper is accepted, the final camera-ready version can (and
% probably should) include acknowledgements. In this case, please
% place such acknowledgements in an unnumbered section at the
% end of the paper. Typically, this will include thanks to reviewers
% who gave useful comments, to colleagues who contributed to the ideas,
% and to funding agencies and corporate sponsors that provided financial
% support.


\bibliography{references}
\bibliographystyle{icml2017}

\end{document}
