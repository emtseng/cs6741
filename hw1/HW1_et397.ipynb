{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1-et397.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OSMDXPy8M7C",
        "colab_type": "text"
      },
      "source": [
        "# HW 1 Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz5Kh9F0xBVf",
        "colab_type": "text"
      },
      "source": [
        "Welcome to CS 6741 HW1. To begin this assignment first turn on the Python 3 and GPU backend for this Colab by clicking `Runtime > Change Runtime Type` above.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiugnUMt8M7E",
        "colab_type": "text"
      },
      "source": [
        "In this homework you will be building several varieties of text classifiers. Text classifiers are not that exciting from an NLP point of view, but they are a great way to get up to speed on the core technologies we will use in this class.\n",
        "\n",
        "\n",
        "\n",
        "## Goal\n",
        "\n",
        "We ask that you construct the following models in PyTorch:\n",
        "\n",
        "1. A naive Bayes unigram classifer (follow Wang and Manning http://www.aclweb.org/anthology/P/P12/P12-2.pdf#page=118: you should only implement Naive Bayes, not the combined classifer with SVM).\n",
        "2. A logistic regression model over word types (you can implement this as $y = \\sigma(\\sum_i W x_i + b)$) \n",
        "3. A continuous bag-of-word neural network with embeddings (similar to CBOW in Mikolov et al https://arxiv.org/pdf/1301.3781.pdf ).\n",
        "4. A simple convolutional neural network (any variant of CNN as described in Kim http://aclweb.org/anthology/D/D14/D14-1181.pdf ).\n",
        "5. Your own extensions to these models...\n",
        "\n",
        "Consult the papers provided for hyperparameters. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG0DhOyL8M7E",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "\n",
        "This notebook provides a working definition of the setup of the problem itself. You may construct your models inline or use an external setup (preferred) to build your system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHTkeBl-8M7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "# Text text processing library and methods for pretrained word embeddings\n",
        "import torchtext\n",
        "from torchtext.vocab import Vectors, GloVe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE37lf0u8M7L",
        "colab_type": "text"
      },
      "source": [
        "The dataset we will use of this problem is known as the Stanford Sentiment Treebank ( https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf ). It is a variant of a standard sentiment classification task. For simplicity, we will use the most basic form. Classifying a sentence as positive or negative in sentiment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXlrvClg8M7M",
        "colab_type": "text"
      },
      "source": [
        "To start, `torchtext` requires that we define a mapping from the raw text data to featurized indices. These fields make it easy to map back and forth between readable data and math, which helps for debugging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbZiWCz18M7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our input $x$\n",
        "TEXT = torchtext.data.Field()\n",
        "\n",
        "# Our labels $y$\n",
        "LABEL = torchtext.data.Field(sequential=False, unk_token=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYweUw-h8M7Q",
        "colab_type": "text"
      },
      "source": [
        "Next we input our data. Here we will use the standard SST train split, and tell it the fields. Torchtext also gives us the option of using subtrees in the treebank as examples as well. The subtrees can be obtained by passing the option `train_subtrees=True` to splits. Feel free to experiment with using subtrees and report their effect on performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQcxFoh88M7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "afcd6e90-88c9-44f2-f17f-7b79b91ca8df"
      },
      "source": [
        "train, val, test = torchtext.datasets.SST.splits(\n",
        "    TEXT, LABEL,\n",
        "    filter_pred=lambda ex: ex.label != 'neutral')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rtrainDevTestTrees_PTB.zip:   0%|          | 0.00/790k [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading trainDevTestTrees_PTB.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "trainDevTestTrees_PTB.zip: 100%|██████████| 790k/790k [00:00<00:00, 3.27MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJOFyfYT8M7V",
        "colab_type": "text"
      },
      "source": [
        "Let's look at this data. It's still in its original form, we can see that each example consists of a label and the original words.\n",
        "\n",
        "Be sure to double check that examples with neutral labels were filtered out. \n",
        "\n",
        "The length of the training data should be 6920."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDgwcxmh8M7W",
        "colab_type": "code",
        "outputId": "66dec36b-840d-4d80-a16f-6f84d435c763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print('len(train)', len(train))\n",
        "print('vars(train[0])', vars(train[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(train) 6920\n",
            "vars(train[0]) {'text': ['The', 'Rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'Century', \"'s\", 'new', '``', 'Conan', \"''\", 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'Arnold', 'Schwarzenegger', ',', 'Jean-Claud', 'Van', 'Damme', 'or', 'Steven', 'Segal', '.'], 'label': 'positive'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tcw37Xr8M7b",
        "colab_type": "text"
      },
      "source": [
        "In order to map this data to features, we need to assign an index to each word an label. The function build vocab allows us to do this and provides useful options that we will need in future assignments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otfqiXh98M7b",
        "colab_type": "code",
        "outputId": "80a7c701-10e1-444f-f1ae-180acb1fa723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "TEXT.build_vocab(train)\n",
        "LABEL.build_vocab(train)\n",
        "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
        "print('len(LABEL.vocab)', len(LABEL.vocab))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(TEXT.vocab) 16284\n",
            "len(LABEL.vocab) 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dBj-iHi8M7f",
        "colab_type": "text"
      },
      "source": [
        "Finally we are ready to create batches of our training data that can be used for training and validating the model. This function produces 3 iterators that will let us go through the train, val and test data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV-CSDuX8M7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
        "    (train, val, test), batch_size=10, device=torch.device(\"cuda\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpXAKSbA8M7i",
        "colab_type": "text"
      },
      "source": [
        "Let's look at a single batch from one of these iterators. The library automatically converts the underlying words into indices. It then produces tensors for batches of x and y. In this case it will consist of the number of words of the longest sentence (with padding) followed by the number of batches. We can use the vocabulary dictionary to convert back from these indices to words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcsZVvaG8M7j",
        "colab_type": "code",
        "outputId": "d27f5c9b-e4c8-4fdf-d3de-3090d20a5802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "batch = next(iter(train_iter))\n",
        "print(\"Size of text batch:\", batch.text.shape)\n",
        "# example = batch.text.get(\"batch\", 1)\n",
        "example = batch.text[:,1]\n",
        "print(\"Second in batch\", example)\n",
        "print(\"Converted back to string:\", \" \".join([TEXT.vocab.itos[i] for i in example.tolist()]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of text batch: torch.Size([37, 10])\n",
            "Second in batch tensor([  76, 2267,    5,  167, 2261,  135,   39, 4280,  129,    5,  128, 2673,\n",
            "          68,  662,  484, 1446,   49, 3302,    2,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1], device='cuda:0')\n",
            "Converted back to string: An ingenious and often harrowing look at damaged people and how families can offer either despair or consolation . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJxDYWUp8M7m",
        "colab_type": "text"
      },
      "source": [
        "Similarly it produces a vector for each of the labels in the batch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_DcwMRh8M7m",
        "colab_type": "code",
        "outputId": "f3ddb802-c496-4583-d150-856a8f184e22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Size of label batch:\", batch.label.shape)\n",
        "# example = batch.label.get(\"batch\", 1)\n",
        "example = batch.label[1]\n",
        "print(\"Second in batch\", example.item())\n",
        "print(\"Converted back to string:\", LABEL.vocab.itos[example.item()])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of label batch: torch.Size([10])\n",
            "Second in batch 0\n",
            "Converted back to string: positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgbiW5PP8M7r",
        "colab_type": "text"
      },
      "source": [
        "Finally the Vocab object can be used to map pretrained word vectors to the indices in the vocabulary. This will be very useful for part 3 and 4 of the problem.  Feel free to experiment with different word vectors and report their effect on performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZVfhI6x8M7s",
        "colab_type": "code",
        "outputId": "b5e00c6d-782e-4e56-ec86-f5956f5167a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Build the vocabulary with word embeddings\n",
        "url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.simple.vec'\n",
        "TEXT.vocab.load_vectors(vectors=Vectors('wiki.simple.vec', url=url))\n",
        "\n",
        "print(\"Word embeddings size \", TEXT.vocab.vectors.size())\n",
        "print(\"Word embedding of 'follows', first 10 dim \", TEXT.vocab.vectors[TEXT.vocab.stoi['follows']][:10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/wiki.simple.vec: 293MB [00:04, 62.4MB/s]                           \n",
            "  0%|          | 0/111051 [00:00<?, ?it/s]Skipping token b'111051' with 1-dimensional vector [b'300']; likely a header\n",
            "100%|█████████▉| 110528/111051 [00:10<00:00, 10983.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Word embeddings size  torch.Size([16284, 300])\n",
            "Word embedding of 'follows', first 10 dim  tensor([ 0.3925, -0.4770,  0.1754, -0.0845,  0.1396,  0.3722, -0.0878, -0.2398,\n",
            "         0.0367,  0.2800])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4s05JN38M71",
        "colab_type": "text"
      },
      "source": [
        "## Assignment\n",
        "\n",
        "Now it is your turn to build the models described at the top of the assignment. \n",
        "\n",
        "Using the data given by this iterator, you should construct 4 different torch models that take in batch.text and produce a distribution over labels. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw_PRRx18M72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_code(model):\n",
        "    \"All models should be able to be run with following command.\"\n",
        "    upload = []\n",
        "    # Update: for kaggle the bucket iterator needs to have batch_size 10\n",
        "    test_iter = torchtext.data.BucketIterator(test, train=False, batch_size=10)\n",
        "    for batch in test_iter:\n",
        "        # Your prediction data here (don't cheat!)\n",
        "        probs = model(batch.text)\n",
        "        # here we assume that the name for dimension classes is `classes`\n",
        "        _, argmax = probs.max('classes')\n",
        "        upload += argmax.tolist()\n",
        "\n",
        "    with open(\"predictions.txt\", \"w\") as f:\n",
        "        f.write(\"Id,Category\\n\")\n",
        "        for i, u in enumerate(upload):\n",
        "            f.write(str(i) + \",\" + str(u) + \"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw-LOY_t6TW3",
        "colab_type": "text"
      },
      "source": [
        "#1. Naive Bayes unigram classifer \n",
        "Follows [Wang and Manning](https://www.aclweb.org/anthology/P12-2018.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCz_64ia6SYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "NaiveBayes\n",
        "Author: Emily Tseng (et397)\n",
        "\n",
        "--\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self, alpha, TEXT, LABEL):\n",
        "        \"\"\"\n",
        "            Initializes with a given smoothing parameter\n",
        "        \"\"\"\n",
        "        self.alpha = alpha\n",
        "        self.vocab = TEXT.vocab\n",
        "        self.labels = LABEL.vocab\n",
        "        # Store which label is which\n",
        "        self.label_map = {\n",
        "            self.labels.itos[0]: 0,\n",
        "            self.labels.itos[1]: 1\n",
        "        }\n",
        "        # Initialize with zero seen pos or neg samples\n",
        "        self.p = self.alpha + np.zeros((len(self.vocab),))\n",
        "        self.q = self.alpha + np.zeros((len(self.vocab),))\n",
        "        # Initialize counts at 1 here also to prevent div by 0 error\n",
        "        self.nplus = 1\n",
        "        self.nminus = 1\n",
        "        self.update()\n",
        "    \n",
        "    def update(self):\n",
        "        self.r = np.log((self.p/np.linalg.norm(self.p, ord=1)) / (self.q/np.linalg.norm(self.q, ord=1)))\n",
        "        self.b = np.log(self.nplus / self.nminus)\n",
        "\n",
        "    def featurize(self, x):\n",
        "        \"\"\"\n",
        "            Input: <vec> x\n",
        "            Output: <vec> fx, featurized using the vocabulary\n",
        "        \"\"\"\n",
        "        output = np.zeros((len(self.vocab),))\n",
        "        for word_idx in x:\n",
        "            output[word_idx] = 1\n",
        "        return output\n",
        "\n",
        "    def train(self, train_iter, val_iter):\n",
        "        \"\"\"\n",
        "            \"Trains\" the model based on the provided train and val sets.\n",
        "        \"\"\"\n",
        "        for batch_idx, train_batch in enumerate(train_iter):\n",
        "            # Update the count vectors...\n",
        "            for i in range(len(train_batch)):\n",
        "                x = train_batch.text[:, i]\n",
        "                fx = self.featurize(x)\n",
        "                y = train_batch.label[i]\n",
        "                if self.labels.itos[y.item()] == 'positive':\n",
        "                  self.p += fx\n",
        "                  self.nplus += 1\n",
        "                else:\n",
        "                  self.q += fx\n",
        "                  self.nminus += 1\n",
        "            # And recalculate r & b\n",
        "            self.update()\n",
        "            # Let's hope to see improvement at every 10 batches\n",
        "            if batch_idx % 50 == 0:\n",
        "              batch_acc = self.evaluate(val_iter)\n",
        "              print('val acc after training batch {}: {}'.format(batch_idx, batch_acc))\n",
        "              # print('\\tself.p: {}\\n\\tself.q: {}\\n\\tself.r: {}\\n\\tself.b: {}'.format(self.p, self.q, self.r, self.b))\n",
        "\n",
        "\n",
        "    def evaluate(self, val_iter):\n",
        "        \"\"\"\n",
        "            Evaluates against a batch of given data.\n",
        "        \"\"\"\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, val_batch in enumerate(val_iter):\n",
        "            for i in range(len(val_batch)):\n",
        "                x = val_batch.text[:, i]\n",
        "                y = val_batch.label[i]\n",
        "                fx = self.featurize(x)\n",
        "                yhat = self.predict(fx)\n",
        "                if y == yhat:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "        \n",
        "        return float(correct / total)\n",
        "\n",
        "    def predict(self, x):\n",
        "        val = np.matmul(self.r.T, x) + self.b\n",
        "        if val >= 0:\n",
        "            return self.label_map['positive']\n",
        "        else:\n",
        "            return self.label_map['negative']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yVvcNRH2M8J",
        "colab_type": "code",
        "outputId": "d40f6c94-1de3-42b3-f547-79b29830bcc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "alpha = 1\n",
        "model = NaiveBayes(alpha, TEXT, LABEL)\n",
        "model.train(train_iter, val_iter)\n",
        "# Evaluate on training set first\n",
        "train_acc = model.evaluate(train_iter)\n",
        "print('NaiveBayes train_acc: ', train_acc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized NaiveBayes model with vocab size 16284, label size 2\n",
            "\tself.p: [1. 1. 1. ... 1. 1. 1.]\n",
            "\tself.q: [1. 1. 1. ... 1. 1. 1.]\n",
            "\tself.r: [0. 0. 0. ... 0. 0. 0.]\n",
            "\tself.b: 0.0\n",
            "val acc after training batch 0: 0.5114678899082569\n",
            "val acc after training batch 50: 0.5825688073394495\n",
            "val acc after training batch 100: 0.6754587155963303\n",
            "val acc after training batch 150: 0.7224770642201835\n",
            "val acc after training batch 200: 0.7431192660550459\n",
            "val acc after training batch 250: 0.7603211009174312\n",
            "val acc after training batch 300: 0.7763761467889908\n",
            "val acc after training batch 350: 0.768348623853211\n",
            "val acc after training batch 400: 0.7786697247706422\n",
            "val acc after training batch 450: 0.7844036697247706\n",
            "val acc after training batch 500: 0.7878440366972477\n",
            "val acc after training batch 550: 0.786697247706422\n",
            "val acc after training batch 600: 0.7924311926605505\n",
            "val acc after training batch 650: 0.7970183486238532\n",
            "NaiveBayes train_acc:  0.9486994219653179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_EV6c1lwd4L",
        "colab_type": "code",
        "outputId": "ee33660a-7a11-42d2-d314-eaf45c7369f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Then run the test set\n",
        "test_acc = model.evaluate(test_iter)\n",
        "print('NaiveBayes test_acc: ', test_acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NaiveBayes test_acc:  0.8215266337177375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIMooTXKwkgX",
        "colab_type": "text"
      },
      "source": [
        "# 2) Logistic Regression\n",
        "\n",
        "A logistic regression model over word types (you can implement this as $y = \\sigma(\\sum_i W x_i + b)$) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kLXCG6pwscd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "LogisticRegression\n",
        "Author: Emily Tseng et397\n",
        "\n",
        "--\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_size, output_size, batch_size):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.vocab_size = input_size\n",
        "    self.linear = torch.nn.Linear(input_size, output_size, bias=True)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x.to(device)\n",
        "    output = self.linear(x)\n",
        "    output = torch.sigmoid(output)\n",
        "    return output\n",
        "  \n",
        "  def featurize(self, x):\n",
        "    \"\"\"\n",
        "      Input: <vec> x\n",
        "      Output: <vec> fx, featurized using the vocabulary\n",
        "    \"\"\"\n",
        "    output = np.zeros((self.vocab_size,))\n",
        "    for word_idx in x:\n",
        "        output[word_idx] = 1\n",
        "    return output\n",
        "  \n",
        "  def featurize_batch(self, batch, train=True):\n",
        "    \"\"\"\n",
        "      Takes in a batch from the training data and featurizes it as binarized counts.\n",
        "    \"\"\"\n",
        "    output = np.zeros((self.batch_size, self.vocab_size)) #e.g. 10 x 6000\n",
        "    for i in range(len(batch)):\n",
        "      x = batch.text[:,i]\n",
        "      fx = self.featurize(x)\n",
        "      output[i] = fx\n",
        "    if train:\n",
        "      return Variable(torch.FloatTensor(output)).cuda(), batch.label\n",
        "    else:\n",
        "      return Variable(torch.FloatTensor(output)).cuda()\n",
        "  \n",
        "  def train_model(self, train_iter, val_iter, epochs, lr):\n",
        "    \"\"\" Trains the model over the given parameters. Returns vector of epoch losses for plotting.\n",
        "    \"\"\"\n",
        "    self.train()\n",
        "    # Use SGD and CrossEnt\n",
        "    crossent = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "      epoch_loss = 0.\n",
        "      for batch_idx, batch in enumerate(train_iter):\n",
        "        optimizer.zero_grad()\n",
        "        batch_fx, batch_y = self.featurize_batch(batch, True)\n",
        "        output = self.forward(batch_fx)\n",
        "        loss = crossent(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "      epoch_loss /= len(train_iter)\n",
        "      losses.append(epoch_loss)\n",
        "      val_acc = self.evaluate(val_iter)\n",
        "      print('val acc after training epoch {}: {}'.format(epoch, val_acc))\n",
        "      print('epoch loss: {}'.format(epoch_loss))\n",
        "    return losses\n",
        "  \n",
        "  def evaluate(self, val_iter):\n",
        "    \"\"\" Evaluates against a batch of given data.\n",
        "    \"\"\"\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      for batch_idx, batch in enumerate(val_iter):\n",
        "        for i in range(len(batch)):\n",
        "          x = batch.text[:, i]\n",
        "          y = batch.label[i]\n",
        "          fx = Variable(torch.FloatTensor(self.featurize(x))).cuda()\n",
        "          output = self.forward(fx)\n",
        "          yhat = output.max(0)[1]\n",
        "          if y == yhat:\n",
        "            correct += 1\n",
        "          total += 1\n",
        "      return float(correct / total)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGLkaQTO86w2",
        "colab_type": "code",
        "outputId": "01e19385-2363-4d26-dcc1-dbf1dc321a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "lr = 5e-2\n",
        "epochs = 20\n",
        "batch_size = 10\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "logreg = LogisticRegression(len(TEXT.vocab), len(LABEL.vocab), batch_size)\n",
        "logreg.to(device)\n",
        "\n",
        "logreg_losses = logreg.train_model(train_iter, val_iter, epochs, lr)\n",
        "test_acc = logreg.evaluate(test_iter)\n",
        "print('final test_acc for LogReg: {}'.format(test_acc))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val acc after training epoch 0: 0.5458715596330275\n",
            "epoch loss: 0.685959963440206\n",
            "val acc after training epoch 1: 0.6422018348623854\n",
            "epoch loss: 0.6742552167418375\n",
            "val acc after training epoch 2: 0.6536697247706422\n",
            "epoch loss: 0.6646205173062452\n",
            "val acc after training epoch 3: 0.6605504587155964\n",
            "epoch loss: 0.6573416831865476\n",
            "val acc after training epoch 4: 0.6880733944954128\n",
            "epoch loss: 0.6509218731884322\n",
            "val acc after training epoch 5: 0.6880733944954128\n",
            "epoch loss: 0.645462427525162\n",
            "val acc after training epoch 6: 0.6754587155963303\n",
            "epoch loss: 0.6405531319579637\n",
            "val acc after training epoch 7: 0.6880733944954128\n",
            "epoch loss: 0.6361205812134495\n",
            "val acc after training epoch 8: 0.7018348623853211\n",
            "epoch loss: 0.6319561226002742\n",
            "val acc after training epoch 9: 0.6972477064220184\n",
            "epoch loss: 0.6279672666781211\n",
            "val acc after training epoch 10: 0.7110091743119266\n",
            "epoch loss: 0.6244509506949111\n",
            "val acc after training epoch 11: 0.7144495412844036\n",
            "epoch loss: 0.6210844695051282\n",
            "val acc after training epoch 12: 0.7110091743119266\n",
            "epoch loss: 0.6177411827910153\n",
            "val acc after training epoch 13: 0.7121559633027523\n",
            "epoch loss: 0.6150268780099863\n",
            "val acc after training epoch 14: 0.7087155963302753\n",
            "epoch loss: 0.6120219971403221\n",
            "val acc after training epoch 15: 0.7121559633027523\n",
            "epoch loss: 0.6091695678974852\n",
            "val acc after training epoch 16: 0.716743119266055\n",
            "epoch loss: 0.6066468924370115\n",
            "val acc after training epoch 17: 0.7178899082568807\n",
            "epoch loss: 0.6040235899517991\n",
            "val acc after training epoch 18: 0.713302752293578\n",
            "epoch loss: 0.6016318555598315\n",
            "val acc after training epoch 19: 0.7224770642201835\n",
            "epoch loss: 0.5992194669095078\n",
            "final test_acc for LogReg: 0.7056562328390994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nvpZ9lfpCQH",
        "colab_type": "text"
      },
      "source": [
        "# 3) CBOW\n",
        "\n",
        "A continuous bag-of-word neural network with embeddings (similar to CBOW in Mikolov et al https://arxiv.org/pdf/1301.3781.pdf )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99rX1-zlpcXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "CBOW NN\n",
        "Author: Emily Tseng et397\n",
        "\n",
        "--\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CBOW(nn.Module):\n",
        "  def __init__(self, embeddings, output_size, batch_size, pad_idx):\n",
        "    super(CBOW, self).__init__()\n",
        "    self.embeddings = nn.Embedding(embeddings.size(0), embeddings.size(1), padding_idx=pad_idx)\n",
        "    self.linear = torch.nn.Linear(embeddings.size(1), output_size, bias=True)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x.to(device)\n",
        "    embedded_x = self.embeddings(x)\n",
        "    # CBOW uses a vector of averaged word embeddings\n",
        "    avg_embed = embedded_x.mean(0)\n",
        "    output = self.linear(avg_embed)\n",
        "    return nn.functional.log_softmax(output, dim=1)\n",
        "  \n",
        "  def predict(self, x):\n",
        "    logits = self.forward(x)\n",
        "    return logits.max(1)[1]\n",
        "  \n",
        "  def train_model(self, train_iter, val_iter, epochs, lr):\n",
        "    \"\"\" Trains the model over the given parameters. Returns vector of epoch losses for plotting.\n",
        "    \"\"\"\n",
        "    self.train()\n",
        "    # Use SGD and CrossEnt\n",
        "    crossent = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "      epoch_loss = 0.\n",
        "      for batch_idx, batch in enumerate(train_iter):\n",
        "        optimizer.zero_grad()\n",
        "        yhat = self.forward(batch.text)\n",
        "        loss = crossent(yhat, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "      epoch_loss /= len(train_iter)\n",
        "      losses.append(epoch_loss)\n",
        "      print('epoch loss: {}'.format(epoch_loss))\n",
        "      val_acc = self.evaluate(val_iter)\n",
        "      print('val acc after training epoch {}: {}'.format(epoch, val_acc))\n",
        "    return losses\n",
        "  \n",
        "  def evaluate(self, val_iter):\n",
        "    \"\"\" Evaluates against a batch of given data.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "      self.eval()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      for batch_idx, batch in enumerate(val_iter):\n",
        "        yhats = self.predict(batch.text)\n",
        "        for i, yhat in enumerate(yhats):\n",
        "          if batch.label[i] == yhat:\n",
        "            correct += 1\n",
        "          total += 1\n",
        "      return float(correct / total)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0cupwauqyvd",
        "colab_type": "code",
        "outputId": "6a13c7ad-fe84-463a-a617-bfc84d8cfbef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "lr = 5e-2\n",
        "epochs = 20\n",
        "batch_size = 10\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pad_idx=TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "cbow = CBOW(TEXT.vocab.vectors, len(LABEL.vocab), batch_size, pad_idx)\n",
        "cbow.to(device)\n",
        "\n",
        "cbow_losses = cbow.train_model(train_iter, val_iter, epochs, lr)\n",
        "test_acc = cbow.evaluate(test_iter)\n",
        "print('\\nfinal test_acc for CBOW: {}'.format(test_acc))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch loss: 0.6739854291512098\n",
            "val acc after training epoch 0: 0.6387614678899083\n",
            "epoch loss: 0.6492111387452638\n",
            "val acc after training epoch 1: 0.6422018348623854\n",
            "epoch loss: 0.6345409881431243\n",
            "val acc after training epoch 2: 0.6571100917431193\n",
            "epoch loss: 0.6255833912274741\n",
            "val acc after training epoch 3: 0.6479357798165137\n",
            "epoch loss: 0.619871094521415\n",
            "val acc after training epoch 4: 0.6307339449541285\n",
            "epoch loss: 0.6148916824015579\n",
            "val acc after training epoch 5: 0.6387614678899083\n",
            "epoch loss: 0.6103021444354443\n",
            "val acc after training epoch 6: 0.6467889908256881\n",
            "epoch loss: 0.6080563691999182\n",
            "val acc after training epoch 7: 0.6387614678899083\n",
            "epoch loss: 0.6038626094343346\n",
            "val acc after training epoch 8: 0.6456422018348624\n",
            "epoch loss: 0.6011746638599847\n",
            "val acc after training epoch 9: 0.6536697247706422\n",
            "epoch loss: 0.5984734961321588\n",
            "val acc after training epoch 10: 0.6456422018348624\n",
            "epoch loss: 0.5953932171525983\n",
            "val acc after training epoch 11: 0.6548165137614679\n",
            "epoch loss: 0.5931417824905043\n",
            "val acc after training epoch 12: 0.6444954128440367\n",
            "epoch loss: 0.5910087475025585\n",
            "val acc after training epoch 13: 0.6536697247706422\n",
            "epoch loss: 0.5887442784803796\n",
            "val acc after training epoch 14: 0.6467889908256881\n",
            "epoch loss: 0.5856433681325416\n",
            "val acc after training epoch 15: 0.6536697247706422\n",
            "epoch loss: 0.5860146665676481\n",
            "val acc after training epoch 16: 0.6525229357798165\n",
            "epoch loss: 0.5818840720060933\n",
            "val acc after training epoch 17: 0.6479357798165137\n",
            "epoch loss: 0.5787457645025557\n",
            "val acc after training epoch 18: 0.643348623853211\n",
            "epoch loss: 0.5779623792350637\n",
            "val acc after training epoch 19: 0.6548165137614679\n",
            "\n",
            "final test_acc for CBOW: 0.6617243272926964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_x5HzJXv4PZ",
        "colab_type": "text"
      },
      "source": [
        "# 4) CNN\n",
        "\n",
        "A simple convolutional neural network (any variant of CNN as described in Kim http://aclweb.org/anthology/D/D14/D14-1181.pdf )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8jY5vC1dQLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sanitize_batch(batch, min_length):\n",
        "  \"\"\"\n",
        "    If a batch contains sentences less than a defined minimum length, pad it.\n",
        "  \"\"\"\n",
        "  if batch.text.size(0) < min_length:\n",
        "    nparr = batch.text.data.cpu().numpy()\n",
        "    nparr = nparr.T\n",
        "    output = np.zeros((nparr.shape[0], min_length))\n",
        "    for i, sentence in enumerate(nparr):\n",
        "      output[i] = np.concatenate((sentence, [pad_idx] * (min_length - nparr.shape[1])))\n",
        "    return torch.LongTensor(output.T).to(device)\n",
        "  else:\n",
        "    return batch.text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZiT30h4v34m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "CNN\n",
        "Author: Emily Tseng et397\n",
        "\n",
        "--\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, embeddings, output_size, pad_idx, init_embed=False):\n",
        "    super(CNN, self).__init__()\n",
        "    vocab_size = embeddings.size(0)\n",
        "    embed_dim = embeddings.size(1)\n",
        "    self.pad_idx = pad_idx\n",
        "\n",
        "    # Shared embedding layer, |V| x embed_dim \n",
        "    self.embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
        "    if init_embed:\n",
        "      self.embeddings.weight.data.copy_(embeddings)\n",
        "\n",
        "    # Convolutional layers. Per Kim:\n",
        "    #   window sizes h=3,4,5 \n",
        "    #   \"100 feature maps\" = output size is 100\n",
        "    self.convs = nn.ModuleList([\n",
        "                                nn.Conv2d(1, 100, kernel_size=(window_size, embed_dim))\n",
        "                                for window_size in [3,4,5]\n",
        "    ])\n",
        "\n",
        "    # Dropout layer with p=0.5 per Kim\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    # And includes 1 linear layer. 3 filters of size=100 each -> 300\n",
        "    self.linear = torch.nn.Linear(300, output_size, bias=True)\n",
        "  \n",
        "  def forward(self, x, train):\n",
        "    # x: (max sentence length, batch size)\n",
        "    x = x.T\n",
        "    # x: (batch size, max sentence length)\n",
        "    x.to(device)\n",
        "\n",
        "    embedded_x = self.embeddings(x).unsqueeze(1)\n",
        "    # embedded_x: (batch size, 1, max sentence length, embed_dim)\n",
        "\n",
        "    # Push the sentence through each of the 3 convs + activate via ReLU per Kim\n",
        "    conved_x = [nn.functional.relu(conv(embedded_x).squeeze(3)) for conv in self.convs]\n",
        "    # conv_3: (batch size, 100, max sentence length - 3 + 1) etc\n",
        "\n",
        "    # Apply max-pooling over each of the layers\n",
        "    pooled_x = [nn.functional.max_pool1d(conv, conv.size(2)).squeeze(2) for conv in conved_x]\n",
        "    # pooled_3: (batch size, 100) etc\n",
        "\n",
        "    # Then concat.\n",
        "    # output: (batch size, 100 * 3)\n",
        "    output = torch.cat(pooled_x, dim=1)\n",
        "\n",
        "    # If training, apply dropout at the penultimate layer for regularization per Kim\n",
        "    if train:\n",
        "      output = self.dropout(output)\n",
        "\n",
        "    # Then apply ultimate linear + softmax\n",
        "    output = self.linear(output)\n",
        "    return nn.functional.log_softmax(output, dim=1)\n",
        "  \n",
        "  def predict(self, x):\n",
        "    logits = self.forward(x, train=False)\n",
        "    return logits.max(1)[1]\n",
        "  \n",
        "  def train_model(self, train_iter, val_iter, epochs, lr):\n",
        "    \"\"\" Trains the model over the given parameters. Returns vector of epoch losses for plotting.\n",
        "    \"\"\"\n",
        "    self.train()\n",
        "    # Use Adadelta (per Kim) and CrossEnt\n",
        "    lossfunc = torch.nn.CrossEntropyLoss()\n",
        "    lossfunc.to(device)\n",
        "    optimizer = torch.optim.Adadelta(self.parameters(), lr=lr)\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "      epoch_loss = 0.\n",
        "      for batch_idx, batch in enumerate(train_iter):\n",
        "        optimizer.zero_grad()\n",
        "        # Sanitize so it's at least 5 long\n",
        "        sanitized_batch = sanitize_batch(batch, 5)\n",
        "        yhat = self.forward(sanitized_batch, train=True)\n",
        "        loss = lossfunc(yhat, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "      epoch_loss /= len(train_iter)\n",
        "      losses.append(epoch_loss)\n",
        "      print('epoch loss: {}'.format(epoch_loss))\n",
        "      val_acc = self.evaluate(val_iter)\n",
        "      print('val acc after training epoch {}: {}'.format(epoch, val_acc))\n",
        "    return losses\n",
        "  \n",
        "  def evaluate(self, val_iter):\n",
        "    \"\"\" Evaluates against a batch of given data.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "      self.eval()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for batch_idx, batch in enumerate(val_iter):\n",
        "        sanitized_batch = sanitize_batch(batch, 5)\n",
        "        yhats = self.predict(sanitized_batch)\n",
        "        for i, yhat in enumerate(yhats):\n",
        "          if batch.label[i] == yhat:\n",
        "            correct += 1\n",
        "          total += 1\n",
        "      return float(correct / total)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYp6ZGdJwKeC",
        "colab_type": "code",
        "outputId": "d91315ab-7ba3-49c8-f8e0-113246ccfefb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "lr = 5e-2\n",
        "epochs = 20\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pad_idx=TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "cnn = CNN(TEXT.vocab.vectors, len(LABEL.vocab), pad_idx, init_embed=False)\n",
        "cnn.to(device)\n",
        "\n",
        "cnn_losses = cnn.train_model(train_iter, val_iter, epochs, lr)\n",
        "test_acc = cnn.evaluate(test_iter)\n",
        "print('\\nfinal test_acc for CNN: {}'.format(test_acc))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch loss: 0.7379388183010795\n",
            "val acc after training epoch 0: 0.6823394495412844\n",
            "epoch loss: 0.5404441770532228\n",
            "val acc after training epoch 1: 0.7029816513761468\n",
            "epoch loss: 0.37976736844533443\n",
            "val acc after training epoch 2: 0.7144495412844036\n",
            "epoch loss: 0.23034781023773843\n",
            "val acc after training epoch 3: 0.6972477064220184\n",
            "epoch loss: 0.11523454824753235\n",
            "val acc after training epoch 4: 0.7087155963302753\n",
            "epoch loss: 0.04644142206343741\n",
            "val acc after training epoch 5: 0.7052752293577982\n",
            "epoch loss: 0.015787602655288113\n",
            "val acc after training epoch 6: 0.7110091743119266\n",
            "epoch loss: 0.005460934482334516\n",
            "val acc after training epoch 7: 0.7064220183486238\n",
            "epoch loss: 0.002522401143329062\n",
            "val acc after training epoch 8: 0.713302752293578\n",
            "epoch loss: 0.0015340543166509522\n",
            "val acc after training epoch 9: 0.7087155963302753\n",
            "epoch loss: 0.0010889839801386891\n",
            "val acc after training epoch 10: 0.7098623853211009\n",
            "epoch loss: 0.0008271247297145205\n",
            "val acc after training epoch 11: 0.713302752293578\n",
            "epoch loss: 0.0006641507979547685\n",
            "val acc after training epoch 12: 0.7098623853211009\n",
            "epoch loss: 0.0005560206734532264\n",
            "val acc after training epoch 13: 0.7087155963302753\n",
            "epoch loss: 0.00047414627652013047\n",
            "val acc after training epoch 14: 0.7098623853211009\n",
            "epoch loss: 0.00041564658215717613\n",
            "val acc after training epoch 15: 0.7087155963302753\n",
            "epoch loss: 0.000368636502566205\n",
            "val acc after training epoch 16: 0.7098623853211009\n",
            "epoch loss: 0.00033232373441333986\n",
            "val acc after training epoch 17: 0.7098623853211009\n",
            "epoch loss: 0.00030049122496707585\n",
            "val acc after training epoch 18: 0.7098623853211009\n",
            "epoch loss: 0.0002752377046024019\n",
            "val acc after training epoch 19: 0.7098623853211009\n",
            "\tpadding batch\n",
            "\tpadding batch\n",
            "\n",
            "final test_acc for CNN: 0.7018121911037891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PgPIhIDJc1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "51840e0c-54a5-43b2-fe6f-1f72764cb37b"
      },
      "source": [
        "lr = 5e-2\n",
        "epochs = 20\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pad_idx=TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "cnn2 = CNN(TEXT.vocab.vectors, len(LABEL.vocab), pad_idx, init_embed=True)\n",
        "cnn2.to(device)\n",
        "\n",
        "cnn2_losses = cnn2.train_model(train_iter, val_iter, epochs, lr)\n",
        "test_acc = cnn2.evaluate(test_iter)\n",
        "print('\\nfinal test_acc for CNN: {}'.format(test_acc))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch loss: 0.6701995651156916\n",
            "val acc after training epoch 0: 0.7052752293577982\n",
            "epoch loss: 0.5995232576149048\n",
            "val acc after training epoch 1: 0.7224770642201835\n",
            "epoch loss: 0.521253361436673\n",
            "val acc after training epoch 2: 0.7408256880733946\n",
            "epoch loss: 0.4516537863265917\n",
            "val acc after training epoch 3: 0.7511467889908257\n",
            "epoch loss: 0.39364450506736776\n",
            "val acc after training epoch 4: 0.7557339449541285\n",
            "epoch loss: 0.3405065650195745\n",
            "val acc after training epoch 5: 0.7557339449541285\n",
            "epoch loss: 0.2907878750493761\n",
            "val acc after training epoch 6: 0.7568807339449541\n",
            "epoch loss: 0.24489140262385842\n",
            "val acc after training epoch 7: 0.7385321100917431\n",
            "epoch loss: 0.20239908056538228\n",
            "val acc after training epoch 8: 0.7614678899082569\n",
            "epoch loss: 0.1644754003830297\n",
            "val acc after training epoch 9: 0.7694954128440367\n",
            "epoch loss: 0.13099715119561536\n",
            "val acc after training epoch 10: 0.7419724770642202\n",
            "epoch loss: 0.10258676475613793\n",
            "val acc after training epoch 11: 0.7786697247706422\n",
            "epoch loss: 0.0796212723580959\n",
            "val acc after training epoch 12: 0.7649082568807339\n",
            "epoch loss: 0.061663015204551766\n",
            "val acc after training epoch 13: 0.7672018348623854\n",
            "epoch loss: 0.047128534153765986\n",
            "val acc after training epoch 14: 0.7786697247706422\n",
            "epoch loss: 0.03637064451074518\n",
            "val acc after training epoch 15: 0.7798165137614679\n",
            "epoch loss: 0.02836299064902944\n",
            "val acc after training epoch 16: 0.7775229357798165\n",
            "epoch loss: 0.022496502228401535\n",
            "val acc after training epoch 17: 0.7660550458715596\n",
            "epoch loss: 0.018177676958037337\n",
            "val acc after training epoch 18: 0.7740825688073395\n",
            "epoch loss: 0.014957725175729054\n",
            "val acc after training epoch 19: 0.7694954128440367\n",
            "\tpadding batch\n",
            "\tpadding batch\n",
            "\n",
            "final test_acc for CNN: 0.7753981328940143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHZcs6FTGfKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "37f7050f-ed56-44ed-e57b-355cefc51d2d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_losses(labeled_losses):\n",
        "  \"\"\"\n",
        "    Input: [(losses, label), (losses2, label2)...]\n",
        "    Plots them\n",
        "  \"\"\"\n",
        "  for (losses, label) in labeled_losses:\n",
        "    plt.plot(range(len(losses)), losses, label=label)\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "plot_losses([\n",
        "             (logreg_losses, \"LR\"),\n",
        "             (cbow_losses, \"CBOW\"),\n",
        "             (cnn_losses, \"CNN\"),\n",
        "             (cnn2_losses, \"CNN*\"),\n",
        "])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3wUZf7A8c93Wza9R0ISCE04sIBG\nrD8BPT1sRAUVPE88CzZU9PQs3Hmenp6ndzbEU1QUCxZsh4p6NlT0VIJiRXpJAoEQCOlt9/n9MZuw\nCamQzSbZ71vnNbPPPDPzzbLJd+d5Zp4RYwxKKaVCly3YASillAouTQRKKRXiNBEopVSI00SglFIh\nThOBUkqFOEewA+iopKQkk5mZGewwlFKqR1m2bNl2Y0xyc+t6XCLIzMwkJycn2GEopVSPIiIbW1qn\nTUNKKRXiNBEopVSI00SglFIhThOBUkqFOE0ESikV4jQRKKVUiNNEoJRSIS5kEsF3hd/xwLIHgh2G\nUkp1OyGTCFYUreDJH59k/a71wQ5FKaW6lZBJBGPSxwCwOHdxcANRSqluJmQSQWpUKsMShmkiUEqp\nJkImEYB1VrC8cDnFVcXBDkUppbqNkEoE4zLG4TVePsv/LNihKKVUtxFSieBXib8iOTyZj3M/DnYo\nSinVbYRUIrCJjTEZY/hi8xfUeGqCHY5SSnULAU0EIjJeRFaKyBoRuamZ9feLyHLftEpEAt54PzZ9\nLOW15eQU6DMNlFIKApgIRMQOzAZOAoYDU0RkuH8dY8y1xpiRxpiRwCzgtUDFU+/w1MNx290szlsc\n6EMppVSPEMgzgtHAGmPMOmNMDfAikN1K/SnACwGMBwC3w80RfY9gce5ijDGBPpxSSnV7gUwEaUCu\n3+s8X9keRKQ/MAD4qIX100QkR0RyCgsL9zmwcRnj2FK+hVU7V+3zvpRSqqfrLp3Fk4FXjDGe5lYa\nY+YYY7KMMVnJyc0+e7lDjk0/FtC7jJVSCgKbCPKBDL/X6b6y5kymC5qF6iWFJ3FQ0kF8kvdJVx1S\nKaW6rUAmgqXAEBEZICIurD/2C5tWEpFhQDzwvwDGwhdrt3PHWz/zxrf5rNlWyv+lH8sP239ge+X2\nQB5WKaW6PUegdmyMqROR6cB7gB2Ya4z5SURuB3KMMfVJYTLwoglwz+2qglKe+3Ij1XVeAMIjXTj6\nwXVvzufUgWdwQN9YhuwXhdPeXVrLlFKqa0hPu3ImKyvL5OTs3T0AdR4vawvL+TF/Fz/kF7OwaDo1\nlftRtul8AFwOG8P6RHNAWiwH9I3lgLQY9t8vGrfT3pk/glJKdTkRWWaMyWpuXcDOCLqdorU4Nn/L\n0F9NYGifdCYemk7YV7/htdWv8fKMw1ldUM1Pm0v4MX8Xb323mflfbQLAYROG7BfNAX1jGN7XSgyD\nU6JIiQ5DRIL8Qyml1L4LmUTg+WIepQvmEHfgTXDIVDj0AsZkjGH+L/MprP2J7JFjyB5pXd1qjCFv\nZyU/5u/ix827+CG/hI9+2caCZXkN+4t2OxicEsXg5ChrnhLFkJRo0uLDsds0QSileo6QSQRFaxMo\n+joe+vYjbsl9sOQ+DhvyGyLtYXy86WPGZIxpqCsiZCREkJEQwUkHpgJWcigsrWbNtjJWbytjjW9a\nvKqwUYIIc9gYmFyfGHYniczESFwO7X9QSnU/IZMIkq+4gspvl7Pl7W9wzXqOCM8ynMvmcXSk4dNV\nr+IlEduo30JEQrPbiwgpMW5SYtwcNTip0bpdFbWsKSxtSA6rt5Xx7aadvPnd5oY6dpvQLyGC9Phw\n0uLCrXl8OGlxEaTFh9Mnxq1nEkqpoAipzmLPrl1sOGcynuJiMl9+CVff/Xhzyd+4ZeMbvJBfwAFe\nGxwwCQ67CNIO2edYK2s8rC3cffawbnsZ+TsryS+uZHtZ49FP7TYhNdZNWpyVINLr5/ERpMWFkxrn\nJsyhndZKqb3TWmdxSCUCgJoNG9hwzmTsiYlkvvgCpS4vY14ewyUDspleXALfvwy15ZB2KBx2MYw4\nA5zhnfgTWKpqPeQXV5K/s5K8nZXkF1c0JIn8nZUUlFTh9funEYHkqDD6xLrpE+O25v7LvnmEK2RO\n8pRSHaCJoInyr79m00UXE3lYFhmPPcbvP7yEspoyXpnwClTtgu9egqVPwPaVEB4Po86DrAshYWAn\n/RRtq/V4KdhV5UsSlb4kUUFBSTVbd1WxZVclJVV1e2wX43aQGhvOfrFuUmPc1tyXKPaLcZMcHUZC\npEuboZQKMZoImlH86mtsmTmTuHPO4b1J/fnXN/fx34n/JTXK6hzGGNjwmZUQVrwFxgMDxsCgcdD/\nGOg7EuzOfY5jX1TU1FGwq4qCkqrGc7/lwrJqmv4T2wQSIsNIinKRHB1GclQYSdG7XydFWVNydBjx\nEZo0lOoN9D6CZsRNPJOaDespevwJjkmdxr/CYXHeYqYMm2JVEIEBx1pTyWb45hn48VX44DZrvTMS\nMkZD/6Mh82irKckR1qU/Q4TLwcDkKAYmR7VYp9bjpbC0mi27qthaUsX2smq2l1ZTWFZNYWkNhWXV\nrCssZ3tZdcNd1/5sAolR9cnBRWKki4TIMBKjXCREWlNiwzyMmHCH3l+hVA8TsmcEAMbrJf+aayj9\n4EOe+l0fSg7bn0dPeLT1jcq2wcbPYcPnsPEL2PaTVe5wQ/phuxND+mEB6VsIFGMMpdV1VpIorWZ7\nWQ3by+qXd8+LymvYUV5DRU2zA8XisAnxvuRgJYuwhkSREOkiPsJFfISTuAgX8ZFO4iNceue2Ul1A\nm4Za4a2oYON5v6Ns7Sr+/Ds7z1/zOZHOyPbvoGKHlRA2fm5NBT+A8YLNaZ0lZB5tJYeMwyGs5W/u\nPU1VrcdKCmU1FJVXs8OXIHaX1bDDV15UXkNpM/0Z9dxOG/ERLis5RFjJITbC2bAc5588IpzEhluT\nQ8eFUqrdNBG0oXbrNlZNPJ0dNTupefQOjj9k0t7vrGoXbPoSNiyxEsPm5Vb/gs0BfQ6EpKGQOBgS\nB0HSEKsD2tWBxNND1dR52VlRY03ltRRX1LCzopadFTUNy43LrNfeVj6e0WEOYiOcxPmSQ1y4lUDi\nwneXxYa7iIvwf+0k3GnX5isVcjQRtEPZj9+zZso5lKbFc/TrH2IL76RmneoyyP3KSgp5OVC0Fkry\nGteJSfMlB9+UNMRKFLH9wB6y3Th4vVZzlX+C2FVRy67KWitRVFqviyvry2oa1tW1kkGcdmlICs1N\nMX7LcRGuRuvcTpsmEdUjaSJop0cemsqYR74m5sQTSX/gfsQWoKaHmgrYsRaK1sD2Nda8aA0UrbbO\nKOrZnNYZQ/0ZRMJAiE6F6P0gaj+ITAnpRNESYwzlNZ7dycGXLIp9SaR+Kqls/Lq4oobS6ro9rrLy\n57AJ0W4H0W6nb757OaaZsmi3kxi/eZTboWckKij0qqF2GjhhCs+vyOF3//0vhQ89RMqMGYE5kCvC\naibqc2DjcmOgogi2r/ZLDr5pzfvgqWmyI4GIRIjuA1EpEOWbN3q9n5U4XFHWlVAhQESICnMQFeYg\nLa5jZ3Zer6G0qq5RgvCfSqtqKa2q85vXkbujgtKqOkqqailrI5GAdRd5VJiVMOrn0W7n7jJfUqn/\nGfYo8yUbvdNcdRZNBH6O7ns0Nx/pZKzJhEcfI2zAAGKzs7suABGITLKm/kc2Xuf1QEm+ddVSaQGU\nbbWWywp2lxWussq9tXvu2xlhJYfIZIhIgshEv2XfFOE3d7q75mfuZmw2ITbCSWzE3t0j4vUaymvq\nGpJEfcIo8c3Lqusoqy+vtuqUVdWxrbSKdYXW+pKqOmqauZS3KZfdRpRfMmmaVOoTRrRvOSrMSaTL\nTkSYgwiXnQiXnUiXg3CXnTCHNnmFMk0EfqJd0WT1OYx//7qAByoPZ8uf/owzPZ2IQw8Ndmhgs0Nc\nP2tqjdcLVcVWQigtaJwsyrZC+XbYlQdbllvLzSUNAFe0lSwikqyEUb8ckeibEhovh8VCoJrSehCb\nTXzNQvt2s2F1nYcyX+LwTypl1Y3LyqprfYmljtLqOjYXV1FaXdpQ1lpfiT+7TfZIDpEuBxFhdl+5\noyGJRIVZy5H1y2EOIsOs15Gu3WU62m7PoX0ETTy/4nnu/vpu3jzuBTyX3LB7gLp+bfwB7omMsfok\nKoqspFBeCBXbfcvbm19uKXGIDcITmiSJBL+yRGu4Dme4dXbiDN89Oernbk0mncgYQ3Wdt1ESqajx\nUFFTR3m1h8oaD+U1rZdZcw8V1XWU13gor25/cnHZbQ0Joj45RLjsRIU5rMQS1jTB2JuU704w9clI\n73Lfe0HrLBaR8cCDWM8sfsIYc3czdc4GbgMM8J0x5tzW9hnoRJBfls/4V8dzfdb1TIkcw/pzJuPw\nDVBnj4kJ2HF7BGOguhQqd1jJo2KHbyqyppbKW0oezXG4dycLh9uXNOrLIiE8zkoojaY4cMfvXueO\ntc6gVKerTy4VvqRQVl3nN7fKymvqy3yv69f7kk2F/7zG065msHphDhvhLjsRTrs19529hDutM5dw\n1+4zGLfT3nCWY6137FGnYb3Ljsveu5vHgpIIRMQOrAJOAPKApcAUY8zPfnWGAC8DxxljdopIijFm\nW2v7DXQiADhz4ZnEhcUx9zdzKf/qazZdvHuAOnEGd3yhHscYqCnzJYqdUFu5e6qrgtqKxmW1FX7l\nVY3Lasqgcpe1n5rSVg4qVjJoLmG4Iq2Oc2eEb9k3OSOscldE4zrO8JDpZA+Wmjqv35mIlUDqz0Cs\n13VUVFvrK+vPUGo8VNbufl1Z65s3LNdRVdv+BAPWFWHNJwkHEX6Jpj7puH3L4c7d5S3N3c7g98ME\n66qh0cAaY8w6XxAvAtnAz351LgFmG2N2ArSVBLrK2PSxzP1xLruqdxF7+GhSb7uNLTNnUvC3O0n9\n623BDq9nEYGwaGuKz+y8/XpqrWatyp3tm3au9yWQCvBUd+QHaDlZNLyO9JW1lmDq60Rbd5g73Jpg\nfFwOGy6Hba876Fvi9ZqGBFFV69mzucuXWMprPFT6ldcnpfoks6uyli3FlQ37qfRNHf0ObRN2J4dm\nkkj9WUy4y7Z72bn7jCbcZeeg9Fj6J3b+DaiBTARpQK7f6zzg8CZ19gcQkc+xmo9uM8a823RHIjIN\nmAbQrwva6sdmjOXxHx5nSf4SThl4ijVA3fp1FD3xJOEHHUjcxIkBj0G1we7cfbVTR3nqrGdO1JRb\niaGmzDrrqCnfPdX6ymt85U3rV5danfH+deoq2x+D2HcnSFeUlRzq52ExTcr86jTqX/FvPvOVaZNY\nA5tNfB3Znf9nrr6JrP4MpLJ299lIm/NaD1V+ZzKVtR62l9VQWVu5R92m7jzjgB6XCNp7/CHAWCAd\n+FREDjTGFPtXMsbMAeaA1TQU6KAOSDqARHcii3MXc8rAUwBIvvZaKn/6iYLb78A9YgTuYcMCHYYK\nFLsD7LFW81Fn8npaSSi+19VlVrNWdZkvoZRBdYlfctniV6fUGreqQz+bq3EHfEMfS8TuDvkW5766\njvDm5033a3eG7FmNiOD2NfnEB+gYxhiqar1+iaaOxMjAjHAcyESQD2T4vU73lfnLA74yxtQC60Vk\nFVZiWBrAuNpkExtjMsbw/ob3qfXU4rQ7EbudtH/+k/VnnEneNdcw4JVXsEdHBzNM1d3Y/L7ldwZj\nrD6S+iRRU9akj6WySf+Kf1l9H0vF7v6Y8kKrrK5yd/9LXWUzNyq2k9j8EozfVWB7nLH4XSlWf4bT\n0hlQWLTVfKZ3zCMiDc1IgRbId3spMEREBmAlgMlA0yuC3gCmAE+JSBJWU9G6AMbUbmPSx/Da6tdY\ntm0ZR6QeAYAjMZG0++9j4/lT2XLLTNIeerBXX2WggkzE16/guxkwULweXwd9lV9nfWWTeYVfEvFP\nNE07+H3rq0qgdGuT+h1IOg534yaxsBjf4IziO0sy1tx4rYRZP8c0KfOrC9Y+w+PBHdf4IgL/iwrq\n17kiQ+aMJ2CJwBhTJyLTgfew2v/nGmN+EpHbgRxjzELfuhNF5GfAA9xgjCkKVEwdcUTqEYTZw/gk\n95OGRAAQceihpFx3HdvuvZedzzxDwtSpQYxSqU5gs+/u3CYxsMeqq9l9hlN/ltOoeay+yaykSfNZ\nqXVTJFh/nMUG+OZia1xmczRfB9/lz9tWQGWxdfFAa5c225yNk4Q7bvcZX6MzmejGZzNh/v060UF/\nkmF76A1lrbjywytZW7yWd858p9E3f2MMedOvouyTT+j/zDNEHDKqS+JRSnUiY6x+mypfUqhPDpU7\n/cr8yquKdyew6rL2Xxzgf3Zjd1oXCtgc1s2TDct237Ldb7m+3LZ7edR5MHDsXv24OujcXhqbMZZP\n8z5lbfFaBscPbigXEfr+/S7WnzmR/OuuY8Brr+JISAhipEqpDhPxfXuPgtj0jm/vqdvdqV9/1lLj\nv+x35lP/2lNrPZ/E6wVvnW/Z41v2Ql11k3JP4zpDftP57wOaCFo1Jn0MYD3L2D8RANhjYkh78AE2\nTjmXzTf8kYw5jyF2vXRPqZBhd+xuNurhdGCXVqREpDAicQSLcxc3uz58xAj2mzmT8s8/Z/ujbTzr\nWCmluilNBG0YkzGG7wu/p6iy+T7suLPPIjZ7Atsfnk3Z5593cXRKKbXvNBG0YVzGOAyGT/M+bXa9\niNDnL38hbPAgNl9/A7UFBV0coVJK7RtNBG0YGj+UPpF9WmweArBFRJD24IN4q6vJv/Y6TG0HRttU\nSqkg00TQBhFhTPoY/rflf1S3MlhZ2MCBpN5xO5Xffsu2++7vwgiVUmrfaCJoh7EZY6msq+SrLV+1\nWi/2lFOIP/dcdjz1FCXvv99F0Sml1L7RRNAOo/uMJsIRwSe5n7RZN+WmG3EfeCBbbr6Fmk2buiA6\npZTaN5oI2sFld3FU36NYnLuYtu7EtrlcpN1/P9jt5F0zA29VVRdFqZRSe0cTQTsd1+84tlVu45tt\n37RZ15WeRt9/3E31ihVsvfOuLohOKaX2niaCdjq+3/GEO8JZuHZhu+pHjx1L4rRpFC9YQPEbbwQ4\nOqWU2nuaCNopwhnBif1P5L0N71HZzsGmkq++iojRoym47a9UrVwV4AiVUmrvaCLogOzB2ZTXlvPR\npo/aVV8cDtL+9U9s0VHkz5iBp6w8wBEqpVTHaSLogEP3O5S+kX35z5r/tHsbR3Iyaf/6FzUbN1Jw\n65/b7GxWSqmupomgA2xi47RBp/Hlli8pKG//UBKRo0eTfO0MSha9Q5EOTqeU6mY0EXRQ9qBsDIa3\n1r3Voe0SL76Y2OwJFD74ELveejtA0SmlVMdpIuigjJgMDkk5hIVrF3aomUdE6HPHHURkZbHl5pup\nWLYsgFEqpVT7BTQRiMh4EVkpImtE5KZm1l8gIoUistw3XRzIeDrLhEETWL9rPT9s/6FD29lcLtIf\nnoUzLY28K6dTs3FjgCJUSqn2C1giEBE7MBs4CRgOTBGR4c1UfckYM9I3PRGoeDrTiZknEmYPa/c9\nBf7scXFkPGb1E+ROu5S6nTs7OzyllOqQQJ4RjAbWGGPWGWNqgBeB7AAer8tEu6I5vt/xvLP+HWo8\nNR3e3tW/P+mPzKZ282byr7oab03H96GUUp0lkIkgDcj1e53nK2tqooh8LyKviEhGczsSkWkikiMi\nOYWFhYGItcOyB2VTUlPS6nMKWhNxyCGk/v3vVOTksOVPf9LLSpVSQRPszuI3gUxjzEHA+8C85ioZ\nY+YYY7KMMVnJycldGmBLDk89nJSIlL1qHqoXe+opJF9zNSUL32T77Ec6MTqllGq/QCaCfMD/G366\nr6yBMabIGFP/tJcngEMDGE+nstvsnDrwVJbkL2F75fa93k/iZZcRe/rpbH/4YXYt3PukopRSeyuQ\niWApMEREBoiIC5gMNPpLJyKpfi8nACsCGE+nyx6Ujcd4eHvd3t8XICKk3v5XIkaPZvPMP1GxdGkn\nRqiUUm1zBGrHxpg6EZkOvAfYgbnGmJ9E5HYgxxizELhaRCYAdcAO4IJAxRMIA+MGcmDSgSxcu5Cp\nI6bu9X7E5SJ91kNsmDyFvOlX0f/FFwgbMKATI1Wq96utrSUvL4+qEH8GiNvtJj09HafT2e5tpKd1\nUmZlZZmcnJxgh9HgxV9e5M6v7mTBaQsYljBsn/ZVk5vLhnMmY4uOIvPFF3HEx3dSlEr1fuvXryc6\nOprExEREJNjhBIUxhqKiIkpLSxnQ5MukiCwzxmQ1t12wO4t7vJMGnITT5uzQQHQtcWVkkD77Yeq2\nFJB35XS81dVtb6SUAqCqqiqkkwBYTc2JiYkdPivSRLCPYsNiGZsxlkXrF1Hrrd3n/UWMGkXff9xN\n5TffsOWWmXpZqVIdEMpJoN7evAeaCDpB9qBsdlTtYEnekk7ZX8xJJ5F87bWUvP0222fN6pR9KqUC\nLyoqao+y2267jbS0NEaOHMnw4cN54YUXghBZ6zQRdIKj0o4iwZ2wT/cUNJU47RJiJ57J9kf+TfHr\n+qhLpXqya6+9luXLl/Of//yHSy+9lNrafW896EyaCDqB0+bklIGnsDhvMcVVxZ2yTxEh9bbbiDjy\nCLbceivlX37VKftVSgXPkCFDiIiIYGc3G2MsYJePhprsQdk8+/OzLFq/iHN/dW6n7FOcTtIffJAN\nU84l7+qryXzxBcIGDuyUfSvVm/31zZ/4eXNJp+5zeN8Y/nLaiH3axzfffMOQIUNISUnppKg6h54R\ndJKhCUMZljCsU5uHAOwxMWQ89ijidJI77VJqC9r/ZDSlVPdw//33M2LECA4//HBmzpwZ7HD2oGcE\nnWjCoAncs/Qe1uxcw+D4wZ22X1d6Ohn/foRNv7+Qjef9jn5PP40rvbnx+5RSwD5/c+9s1157Lddf\nfz0LFy7koosuYu3atbjd7mCH1UDPCDrRyQNOxiGOTj8rAAg/6CD6PTUXT0kJG8//HTWbNnX6MZRS\ngTVhwgSysrKYN6/Z8TWDRhNBJ0oMT+SY9GN4a91b1HnrOn3/9cnAVFSy8bzfUb1ufacfQym19yoq\nKkhPT2+Y7rvvvj3q3Hrrrdx33314vd4gRNg8bRrqZNmDslmcu5gvt3zJMWnHdPr+w0eMoN+8eWy6\n8EI2nn8+/eY+iXv//Tv9OEqpjmvPH/dDDz2UlStXdkE07adnBJ3s2PRjiQ2LZeGawA0p7R66P/2f\nfQYRYdP5U6n6+eeAHUsp1ftpIuhkLruLkzJP4sNNH1JS07mXr/kLGziQ/s89i4SHs/GC31P5ww8B\nO5ZSqnfTRBAApw8+nRpvDe9teC+gx3H170//Z5/FHhPDpgt+T8U33wb0eEqp3kkTQQAMTxzOoNhB\nAW0equdKT6P/s8/gSEpi08UXU/711wE/plKqd9FEEAAiwoTBE1heuJyNJRsDfjxnair9nn0GZ2oq\nudMupezzzwN+TKVU76GJIEBOHXgqNrF1ynMK2sOZkkL/Z+bh6t+fvMuvoHTx4i45rlKq59NEECAp\nESkc2fdI3lr3Fl7TNdcLOxIT6ff0U4QNGULeVVdT8v77XXJcpZSloKCAyZMnM2jQIA499FBOPvlk\nVq1aRXh4OCNHjuTggw/mqKOOanT56JIlSxg9ejTDhg1j2LBhzJkzB4Di4mISExMbnknyv//9DxEh\nLy8PgF27dpGQkNAp9yMENBGIyHgRWSkia0TkplbqTRQRIyLNPkatp8oelM2W8i0sLei6B9I74uPp\n99RcwocPJ3/GtZQsWtRlx1YqlBljOOOMMxg7dixr165l2bJl/P3vf2fr1q0MGjSI5cuX89133zF1\n6lTuuusuwEoc5557Lo8++ii//PILS5Ys4bHHHuPtt98mLi6O1NRUVqxYAcAXX3zBqFGj+OKLLwD4\n8ssvGT16NDbbvv8ZD1giEBE7MBs4CRgOTBGR4c3UiwauAXrdOMvjMsYR7YwOyJATrbHHxJDx5JOE\njxpJ/vU3sOs/XdM8pVQo+/jjj3E6nVx22WUNZQcffDAZGRmN6pWUlBDvex757NmzueCCCzjkkEMA\nSEpK4p577uHuu+8G4Kijjmr4w//FF19w7bXXNnp99NFHd0rsgbyzeDSwxhizDkBEXgSygaZ3P90B\n/AO4IYCxBIXb4ebEzBNZtH4Rtxx+C5HOyC47tj0qkn5z5pB7xZVsvulmvDU1xJ91VpcdX6mgeucm\nKOjke2v6HAgn3d3i6h9//JFDDz202XVr165l5MiRlJaWUlFRwVdfWd97f/rpJ6ZOndqoblZWFj/9\n9BMARx99NJ988gkXX3wx69at46yzzuKxxx4DrERw000tNrR0SLvOCERkkIiE+ZbHisjVIhLXxmZp\nQK7f6zxfmf9+DwEyjDFvt3H8aSKSIyI5hYWF7Qm52zh98OlU1lXy/saub6+3RUSQ8ei/iTzmGAr+\nfCs7nn++y2NQStHQNLR27VoeeOABpk2b1q7t6s8I1q9fT2ZmJm63G2MMZWVlLFu2jMMPP7xT4mvv\nGcGrQJaIDAbmAP8B5gMn7+2BRcQG3Adc0FZdY8wc33HJysrqUU9zPzj5YPrH9Gfh2oWcPvj0Lj++\nze0mffbD5M+4lq13/A3PzmKSrrxCH/KterdWvrkHyogRI3jllVfarDdhwgR+//vfAzB8+HCWLVtG\ndnZ2w/ply5YxYoQ1jPaQIUMoLi7mzTff5MgjjwSssYqeeuopMjMzm31G8t5obx+B1xhTB5wBzDLG\n3ACktrFNPuDfOJbuK6sXDRwALBaRDcARwMLe1mEsIpw28DSWFiwlvyy/7Q0CwOZykf7gA8Sefjrb\nH36YgltvxdR1/uioSoWy4447jurq6oarfgC+//57cnNzG9VbsmQJgwYNAuDKK6/k6aefZvny5QAU\nFRVx44038sc//rGh/hFHHMGDDz7YkAiOPPJIHnjggU7rHwCsnu62JqyO3CnAj8AAX9mPbWzjANYB\nAwAX8B0wopX6i4GstmI59NBDTU+TX5pvDnj6APPv5f8Oahxer9dsfeAB8/PQYWbTtEuNp7w8qPEo\n1Zl+/vnnYIdg8vPzzVlnnWUGDhxohg8fbk4++WSzatUq43a7zcEHH2wOOuggk5WVZb788suGbT75\n5BOTlZVlhg4davbff3/zyI/l0YQAACAASURBVCOPNNrnPffcY5xOp6moqDDGGLN+/XoDmPnz57cY\nR3PvBZBjWvi7Ksa03dLiu9rnMuB/xpgXRGQAcLYx5h9tbHcy8ABgB+YaY+4Ukdt9AS1sUncxcL0x\nJqe1fWZlZZmcnFardEsXv3cx+WX5LDpzUdCbZXa++BIFt9+Oe8QIMh79N47ExKDGo1RnWLFiBb/6\n1a+CHUa30Nx7ISLLjDHNtri0q2nIGPOzMeZqXxKIB6LbSgK+7RYZY/Y3xgwyxtzpK7u1aRLwlY9t\nKwn0ZNmDs8kryyNna/B/xPjJ55D+8CyqV69mw5RzqdkY+GEwlFLdV3uvGlosIjEikgB8AzwuIns+\neke16IT+JxDtimbBqgXBDgWA6OOOo99Tc/GWlLBhyrk6jLVSIay9ncWxxpgS4EzgGWPM4cCvAxdW\n7+N2uJkwaAIfbPyAnVU7gx0OABGjRtH/hfnYIiLYeP5UHZ9IqRDV3kTgEJFU4GzgrQDG06tNGjKJ\nWm9tl99p3JqwAQPIfGE+YQMGkHfldIrbcfmbUqp3aW8iuB14D1hrjFkqIgOB1YELq3caHD+YUSmj\neGXVK7Snk76rOJKT6ffMM0QeeSRb/vRnCh+e3a3iU0oFVns7ixcYYw4yxlzue73OGDMxsKH1TpP2\nn8SGkg3dotPYnz0qkox/P6L3GigVgtrbWZwuIq+LyDbf9KqIpAc6uN7oxP4ndqtOY3/idJL697tI\nvPwyihe8Qt6V0/FWVAQ7LKV6jJaGoRYRZs2a1VBv+vTpPP300wBccMEFpKWlUV1dDcD27dvJzMzs\n0rjb2zT0FLAQ6Oub3vSVqQ7qjp3G/kSElGuuoc9tt1H22WdsnHoBdUVFwQ5LqW7PtDIMdUpKCg8+\n+CA1NTXNbmu325k7d24XR7xbexNBsjHmKWNMnW96GkgOYFy9WnfsNG5K7zVQqmNaG4Y6OTmZ448/\nnnnz5jW77YwZM7j//vupC1JzbHsHnSsSkfOAF3yvpwD6NXEv+Xcanz/8/KDfadyS+nsN8i6/gg1T\nziXjsUcJP/DAYIelVJv+8fU/+GXHL526z2EJw7hx9I0trm9tGGqAG2+8kZNOOokLL7xwj3X9+vXj\nmGOO4dlnn+W0007rlHg7or1nBBdiXTpaAGwBJtGOUUNVy7prp3FTTe810MdfKrV3Bg4cyOGHH878\n+fObXX/zzTdz7733dsqjJzuqXWcExpiNwAT/MhGZgTWOkNoLJ/Y/kbu/vpsFKxdwWJ/Dgh1Oq+rv\nNcidPp38q66mZsYMEi+d1m3PZJRq7Zt7oLRnGOpbbrmFSZMmMWbMmD3WDRkyhJEjR/Lyyy8HKsQW\n7cujKq/rtChCUEOn8aYP2FG1I9jhtMmRnEz/efOIOfVUCh94gM03/BFvVVWww1Kq22jPMNTDhg1j\n+PDhvPnmm83uY+bMmfzzn/8MeKxN7Usi0K+D+6i+0/jNtc1/KLobm9tN33vvIXnGDEreeouN50+l\ndtu2YIelVLcgIrz++ut88MEHDBo0iBEjRnDzzTfTp0+fRvVmzpxJXl5es/sYMWJEw/OLu1K7hqFu\ndkORTcaYfp0cT5t66jDULTn/nfPZWbWThacv7FFNLSXvv8/mP96IPTaWjEdm4x4+PNghqRCnw1Dv\n1qnDUItIqYiUNDOVYt1PoPZRT+k0birmhBPInP88iLDht+dR8t5/gx2SUmovtZoIjDHRxpiYZqZo\nY0x7Lz1VrWi403hl97vTuC3uX/2KAQtexj10KPnXXEPhI4/oGEVK9UD70kegOkFP6zRuypGURL95\nTxObPYHtD81i8x+u105kpXqYgCYCERkvIitFZI2I3NTM+stE5AcRWS4iS3yPxAw5DXcar+m+dxq3\nxhYWRurdd5N83XWUvPMOG393PrVbtRNZqZ4iYIlAROzAbOAkYDgwpZk/9PONMQcaY0YC9wAh+dSz\nhjuNV3ev4ak7QkRImnaJNSzF2rVsOPtsKn/8KdhhKaXaIZBnBKOBNb4hq2uAF4Fs/wq+p57ViwR6\n5l/BTjBp/0lsLNnY4zqNm4o+/ngyX5gPdhsbzzuPknffDXZISqk2BDIRpAG5fq/zfGWNiMiVIrIW\n64zg6gDG06315E7jptxDhzJgwQLcw4eTP+NafdCNChmdPQx1/e/Nbbfd1uh1Zwt6Z7ExZrYxZhBw\nI/Cn5uqIyDQRyRGRnMLCwq4NsIv09E7jphyJifR7+qmGB93kX3cd3srKYIelVMAEYhjqBx54gCef\nfJLy8nJmzpzJ+wEa6yuQiSAfyPB7ne4ra8mLwOnNrTDGzDHGZBljspKTe+/o1z2907gpm8tF6t/v\nIuWGGyh99z02nvc7avNb+wgo1XMFYhjqa6+9lsLCQh566CHGjx/PiSeeGJDYA3kvwFJgiIgMwEoA\nk4Fz/SuIyBBjTP2zj08hxJ+D7N9pPHXE1B51p3FLRITEiy7ENXAAm2/4I+vPnEjff95L1P/9X7BD\nU71YwV13Ub2ic4ehDvvVMPrcckuL6wMxDPWDDz5IcnIyV199Ne+++y5VVVWccMIJ+/aDNCNgZwTG\nmDpgOtZD71cALxtjfhKR20WkfiTT6SLyk4gsxxrEbmqg4ukp6juNlxYsDXYonSp63DgGvLIAR58+\n5E67lMKHZmE8nmCHpVSX2ZthqK+++mouuugiIiMjufPOO/n1r38dkNgCenewMWYRsKhJ2a1+y9cE\n8vg9Uf3w1K+seoXRqaODHU6ncmVmkvnSixTcfgfbH3mEyuXL6fvPe3EkJAQ7NNXLtPbNPVACMQx1\nfatAfWdxoFoJgt5ZrBrrbZ3GTdncbvredSepd/6NimXLWH/GmVR8+22ww1Jqn4XqMNQqQHpbp3Fz\n4iZOJPPFFxCXi42/O58dzzyjl5iqHi0kh6EOlt42DHVLzn/nfHZU7eDN09/sFZ3GLfGUlLD55lso\n+/BDosePJ/Vvd2CPigp2WKoH0mGod+vUYahV8PTWTuOm7DExpD88i5Qbrqf0/ffZMOksqlauCnZY\nSoUUTQTdVP2dxq+sar3zqTewLjG9iP5PP4WnvIwN55zDrv/8J9hhKRUyNBF0U/Wdxu9ver9Xdho3\nJ+Kwwxj42muEH3ggm2+8iS1/uQ2v77Z7pVTgaCLoxiYNmUSdt65Xdxo35UhOpt9Tc0m85BKKX3qJ\njVPOpaaFjjWlmuppfZ6BsDfvgSaCbqw3DE+9N8ThIOUP15H+yGxqcnNZf+ZESj/6ONhhqW7O7XZT\nVFQUUr8rTRljKCoqwu12d2g7fdxkNzdp/0nMXDKTpQVLe90NZm2JPu44Brz2KvnXzCDviitIvOQS\nkq+5GnHox1btKT09nby8PHrrwJTt5Xa7SU9P79A2evloN1dVV8VxC47jmL7HcM+Ye4IdTlB4q6vZ\n+rc7KV6wgPCDD6bvP+/FlZHR9oZKqQZ6+WgPFoqdxk3ZwsJIveN20u77F9Xr1rE++3SKX38jpJsA\nlOpMmgh6gFDsNG5OzMknM/A/b+AePpwtN99M/nXX4dm1K9hhKdXjaSLoAfw7jb3G2/YGvZizb1/6\nzXua5Ouuo/T9D1iXfTrlX30d7LCU6tE0EfQQZw89m40lG/lo00fBDiXoxG4nadolZL7wArawMDZd\ncAHb/nUfpoWnPymlWqeJoIcYnzmezJhMHv72YTxeHccfIPzAAxjw2qvETZpE0eOPs2HKuVSvWx/s\nsJTqcTQR9BAOm4MrR17J2l1rWbR+UdsbhAhbZKTVkTzrIWrz8lg/cSI7X35ZO5KV6gBNBD3IiZkn\nMjR+KI8sf4Rab22ww+lWYk44gQELFxIxaiQFt/6FvKuuom7nzmCHpVSPoImgB7GJjemjppNXlscb\na94IdjjdjnO/FDKeeIKUG2+k/JNPWT8hm7LPPw92WEp1ewFNBCIyXkRWisgaEbmpmfXXicjPIvK9\niHwoIv0DGU9vMCZ9DAclHcRj3z1GtUcHZGtKbDYSf38BmS+/hC0mhtyLLmbr3f/Aqx3JSrUoYIlA\nROzAbOAkYDgwRUSGN6n2LZBljDkIeAUIzVtnO0BEuOqQq9hasZWXV77c9gYhyv2rXzHglQXEn3su\nO55+mg1nnU316tXBDkupbimQZwSjgTXGmHXGmBrgRSDbv4Ix5mNjTIXv5ZdAxwbICFFHpB7B6D6j\neeKHJ6iorWh7gxBlCw+nz61/Jv3fj1BXWMj6SWexfc7jmFrtX1HKXyATQRqQ6/c6z1fWkouAd5pb\nISLTRCRHRHJCfUCpeleNuoodVTt4fsXzwQ6l24seN46BC/9D1LHHUnjffayfdBaV338f7LCU6ja6\nRWexiJwHZAH3NrfeGDPHGJNljMlKTk7u2uC6qZEpIzk2/Vie+ukpSmpKgh1Ot+dISiJ91kOkPzwL\nT3ExG86ZTMGdd+EpKw92aEoFXSATQT7gP0Rkuq+sERH5NTATmGCM0d7PDrhq1FWU1pQy76d5wQ6l\nx4j+9a8Z+PZbxE+Zws7nnmPdaadR+rE+60CFtkAmgqXAEBEZICIuYDLQaNQ0ERkFPIaVBLYFMJZe\naVjCME7sfyLP/fxcyI5MujfsUVH0ufXP9J//PPaoSPIuv4K8GddSu00/gio0BSwRGGPqgOnAe8AK\n4GVjzE8icruITPBVuxeIAhaIyHIRCe3hNffClaOupMpTxZM/PBnsUHqciFGjGPDqqyTPuIayjz5i\n3SmnWncle0N7YD8VevTBNL3AzCUzeXf9uyw6cxH7Re4X7HB6pOr16yn4y21UfP01EVlZ9Ln9r4QN\nHBjssJTqNPpgml7u8oMvx4uXOd/PCXYoPVbYgAH0m/c0qXf+jarVq1mffTqFs2friKYqJGgi6AXS\no9OZOGQir61+jdzS3LY3UM0SEeImTmTQ228RfcIJbJ/1MOvOPJOKb74JdmhKBZQmgl5i2kHTsNvs\nPPrdo8EOpcdzJCWRdt+/yHjsUbwVFWw897dsue02PKWlwQ5NqYDQRNBLpESkMHnoZN5a9xbritcF\nO5xeIWrMGAa9+SYJU6dS/PIC1p18CsVvvKGdyarX0UTQi1x44IW47W4eXv5wsEPpNWyRkex3801k\nvvQSjj592HLTzWyYdJY+HlP1KpoIepEEdwLnDT+P9ze+z4qiFcEOp1cJP/AAMl96kb733kPdzp1s\nmjqV3CunU71en4imej5NBL3M1BFTiXZFM+vbWcEOpdcRm43Y005j0DuLSL72Wir+9z/WnTaBgjvv\n0ofgqB5NE0EvE+OK4cIDLuSz/M9Yvm15sMPplWxuN0mXTmPQf98jbuJEdj7/PGt/M56iuU/pcw9U\nj6SJoBc6d9i5JLgTeOjbh/TZvQHkSEoi9a+3MeCN1wk/+GC23XMP6045lZJ339P3XfUomgh6oQhn\nBJcceAlLC5by5ZYvgx1Or+fef3/6PT6HjMcfx+Z2kz9jBht/e54Oda16DE0EvdRZQ89iv4j9ePjb\nh/XbaReJ+r9jGPD6a/S5/a/UbNzIhrPPIf8P11Obv8egu0p1K5oIeqkwexiXHXwZ32//nk/yPgl2\nOCFDHA7izz6bQe+9R+Jll1L6wQesPelktv3rPjxlZcEOT6lmaSLoxbIHZ5MRncGsb2fhNXoTVFey\nR0WSMmMGg959h+jxv6Ho8cdZe+Jv2P7445oQVLejiaAXc9qcXDHyClbtXMV/N/w32OGEJGdqKmn3\n3EPmggW4hw2j8F/3sea449n24IPU7dBnSKjuQYeh7uU8Xg+T3pxEnbeO17Nfx2FzBDukkFb5w48U\nzZlD6fvvI243cWefReLvf48zNTXYoaleToehDmF2m53pI6ezoWQDb659M9jhhLzwAw8gfdZDDHz7\nLWLGj2fn8/NZc+Jv2Dxzpt6lrIJGzwhCgDGGKW9PYWfVTl7Pfp0IZ0SwQ1I+NXn57Jg7l+JXX8XU\n1BD9m9+QNO0S3MOHBzs01cvoGUGIExH+kPUHCioKuPGzG/F4PcEOSfm40tPoc+ufGfzhByRefDHl\nn33G+jMnsmnaNCr0C4/qIgFNBCIyXkRWisgaEbmpmfXHisg3IlInIpMCGUuoO6zPYdw0+iYW5y7m\nnqX36L0F3YwjKYmUP1zH4I8/InnGDKp++JGN5/2ODb89j7JPP9V/LxVQAUsEImIHZgMnAcOBKSLS\n9Hx3E3ABMD9QcajdpgybwtThU5n/y3yeW/FcsMNRzbDHxJB02aUM/uhD9rvlFmo3byZ32qWsP3Mi\nJYsWYWprgx2i6oUCeUYwGlhjjFlnjKkBXgSy/SsYYzYYY74H9CL3LnJd1nWc0P8E7l16Lx9s/CDY\n4agW2MLDSTj/dwx+711S77wTU1lJ/nV/YPW449h6771Ur9OHD6nOE8hEkAb4P0A3z1fWYSIyTURy\nRCSnsLCwU4ILVTaxcdcxd3Fg8oHc9NlNfF+o4+F0Z+JyETfxTAa+/RbpjzxC+MEHs+Ppeaw7+RQ2\nTJ5C8Suv4CkrD3aYqofrEZ3Fxpg5xpgsY0xWcnJysMPp8dwON7OOm0VKRApXfXQVuSX6wPvuTux2\noo8bR8bshxmy+GNSbrgeT0kJW/70Z1Yfeyybb5lJxbJl2peg9kogE0E+kOH3Ot1XprqBBHcCjxz/\nCB7j4YoPr2BX9a5gh6TayZGcTOJFFzHw7bfo/8J8Yk85mdJ332Xjb89j3Ukns/3xx6ndti3YYaoe\nJJCJYCkwREQGiIgLmAwsDODxVAdlxmby0LiHyC/L5+qPrqbGow9V6UlEhIhRo0i94w6GfPYpqXfd\nhT0p0RrGYtxx5F5+BaUffKAdzKpNAb2hTEROBh4A7MBcY8ydInI7kGOMWSgihwGvA/FAFVBgjBnR\n2j71hrLO9+76d7nh0xs4acBJ3P1/d2OTHtFiqFpQvX49u157nV1vvEFdYSH2xERis7OJO/MMwgYP\nDnZ4Kkhau6FM7yxWADz5w5M88M0DXHLgJVx9yNXBDkd1AlNXR9mSJex69VVKP14MdXW4Bg0ietxY\nosaOJXzkSMShY0+FitYSgX4KFAAXHnAheWV5PP7D4/SN6suk/fX+vp5OHA6ix44leuxY6oqKKFn0\nDmUff0TRvGcoeuJJ7LGxRI45luhx44g85hjs0dHBDlkFiZ4RqAZ13jqmfzSdLzd/yezjZ3N02tHB\nDkkFgKesjPIlSyj7+GPKPvkUT3ExOBxEHJZF9LhxRI0bhysjo+0dqR5Fm4ZUu5XXlnPBuxewqWQT\nz5z0DEMThgY7JBVAxuOhcvlyyj7+mNKPF1Ozdi0ArsGDiB47lqhx46wmJLs9yJGqfaWJQHXI1vKt\n/HbRbzEYnj/5efpE9gl2SKqL1GzaRNnixZR+/DEVS3Ogrg57XBxRY44latw4Ig4/HEd8fLDDVHtB\nE4HqsJU7VjL13amkRaUxb/w8olxRwQ5JdTFPaSnlS5ZQ+vHHlH/yKZ5d1r0mrsGDiMjKIuKww4jI\nOgznfilBjlS1hyYCtVe+2PwFV35wJYenHs6s42fhtDmDHZIKElNXR+X3P1CxdCkVOTlUfvMN3nJr\naAtnv35WYsjKImL0YTjT0hCRIEesmtJEoPba66tf59YvbmXikIn85ci/6C+4AqzEUPXLSipyllKx\nNIfKnJyGMwZHnz6NEoNrwAD93HQDevmo2mtnDDmDvLI85nw/h7SoNC456JJgh6S6AXE4CD9gBOEH\njCDxggswXi/Va9ZYZws5OZR/9SUlb70FgD0hwZcYDsU9YgRh+++vl6p2M3pGoNpkjOHmJTfz9rq3\nOSL1CKaPms7ByQcHOyzVjRljqN24kYqcHCqW5lCRk0Nt/u6hxpx9+xI2dChhQ/fHPXQoYUOH4erf\nT69OCiBtGlL7rNZby/wV85n741x2VO3g2PRjuXLklQxP1Gfrqvap3bqV6l9+oWrlKqpXrqR61Uqq\n160Hj/XoVAkLI2zIkN3JYX8rUehVSp1DE4HqNBW1Fcz/ZT5P/fgUJTUlHN/veK4YeQX7x+8f7NBU\nD+StrqZm3TqqflnZkByqflmJZ8eOhjqOlBTChg7FPXR/nP3748rIwJWRgaNPHz2D6ABNBKrTldaU\n8tzPz/HMz89QXlvO+MzxXD7ycgbEDgh2aKoXqNu+naqVK6n2nT1UrVpFzZo1jUdSdTpx9k3FlZ6B\ns1+GNc9Ix5WRgTMjA3uUXvLsTxOBCphd1buY99M8nlvxHNWeak4deCqXHXQZGTE6RIHqXMbjoa6g\ngJrcXGpyc6nNzaMmdxO1uXnU5uY2XLVUzx4fjzMjA1d6ui9RpOPYrw+OlGQcycnY4+IQW+iMtKuJ\nQAXcjqodzP1hLi+ufBGP10P24GwuPehSUqNSgx2aChGekpI9E0ReLjWbcqndsqWhL6KBw4EjKQlH\ncvLuKcVvOTnFmicm9IpRWjURqC5TWFHIEz88wYJVCwCYOGQilxx0CSkRevepCh5TW0ttQQF127ZR\nV1hI3bZCa14/+co9xcV7bmyzYU9IsJJCfBz2uDhssbHY4+Kw7zGPwx4fhz06utslD00EqssVlBfw\n2PeP8cbqN7Db7Jwz9BwuPOBCEsMTgx2aUi0yNTXUbd/eOEk0JAsrUXiKi/Hs2oWnpAS83hb3ZYuJ\n2SNR2KKjsEdGYouKwhYZZc2jIneX1ZdHRmKLCO/UpitNBCpocktzeey7x3hz3ZvYxMbA2IEMjhvM\nkPghDIkbwuD4wfSN7Kt3nqoex3i9eEtLraRQnxyKi/EUN3ntN/eWleEtK8PUtOOxsCJWQvAlC1tk\nJIkXX0zMCSfsVbyaCFTQrd+1njfWvMGqnatYU7yGgvKChnURjggGxw+2EoMvSQyOG6xnD6rXMjU1\neMrL8ZaXNyQHT1mZ77WvrNx67SkrayiLP++3RI8bt1fHDFoiEJHxwINYzyx+whhzd5P1YcAzwKFA\nEXCOMWZDa/vURNA7lNaUsrZ4LauLV7Nm5xpWF69m9c7VFFfvbqNNcCc0SgwDYgcQ44ohwhlBpCOS\nCGcELrsriD+FUj1HUMYaEhE7MBs4AcgDlorIQmPMz37VLgJ2GmMGi8hk4B/AOYGKSXUf0a5oRqaM\nZGTKyIYyYwxFVUWsKV7TkBzW7FzDa6tfo7Kustn9OGwOIp2RRDgiGuYRzsbL/onDYXNgF3vD3G6z\nlh3i91oc1nqbfY+6NmzYxIaIYBMbNvyWxYYgLa4XBBFBsJrB6uvV/2f9L43qaZOZ6gqB7NYeDawx\nxqwDEJEXgWzAPxFkA7f5ll8BHhYRMT2tvUp1ChEhKTyJpPAkjkg9oqHca7xsKd/Cxl0bKa0tpaK2\ngoq6CipqKyivLaeizppX1lVSXltOeW05RVVFVj1fnRpvO9pku6lGicGXMBrKfS/8E4x/8vBPJv71\nkcb799+u4bVfpeYSUkvH22O5mWO1tN891rdRvzVNt21p++bqdbRuu2NqR/ytHePygy9n/IDx+xRD\ncwKZCNKAXL/XecDhLdUxxtSJyC4gEdjuX0lEpgHTAPr16xeoeFU3ZRMbaVFppEWl7fU+ar21VNZV\n4vF68BgPdd466rx1eIwHj9dDrbe2YdljWnjt9eDFC8ZKTl68GGOsZePF4LdsDF78ln3rjTE0/Gda\nmGOw/m+8HVhlQEPdhjLfV6emdf3r16sv8y9vWs+/TtO6jeo3s69G27Syvukx2lrfnJa+MzYbfxs/\nU5vHbiOctuLdl5+nXowrps197I3udaFrC4wxc4A5YPURBDkc1QM5bU6cLn2wjlLNCeT91fmA/zgD\n6b6yZuuIiAOIxeo0Vkop1UUCmQiWAkNEZICIuIDJwMImdRYCU33Lk4CPtH9AKaW6VsCahnxt/tOB\n97AuH51rjPlJRG4HcowxC4EngWdFZA2wAytZKKWU6kIB7SMwxiwCFjUpu9VvuQo4K5AxKKWUal3o\njMGqlFKqWZoIlFIqxGkiUEqpEKeJQCmlQlyPG31URAqBjXu5eRJN7lruZjS+faPx7bvuHqPGt/f6\nG2OSm1vR4xLBvhCRnJZG3+sONL59o/Htu+4eo8YXGNo0pJRSIU4TgVJKhbhQSwRzgh1AGzS+faPx\n7bvuHqPGFwAh1UeglFJqT6F2RqCUUqoJTQRKKRXiemUiEJHxIrJSRNaIyE3NrA8TkZd8678Skcwu\njC1DRD4WkZ9F5CcRuaaZOmNFZJeILPdNtza3rwDGuEFEfvAdO6eZ9SIiD/nev+9F5JAujG2o3/uy\nXERKRGRGkzpd/v6JyFwR2SYiP/qVJYjI+yKy2jePb2Hbqb46q0VkanN1AhDbvSLyi+/f73URiWth\n21Y/CwGO8TYRyff7dzy5hW1b/X0PYHwv+cW2QUSWt7Btl7yH+8QY06smrCGv1wIDARfwHTC8SZ0r\ngEd9y5OBl7owvlTgEN9yNLCqmfjGAm8F8T3cACS1sv5k4B2sp9EeAXwVxH/rAqwbZYL6/gHHAocA\nP/qV3QPc5Fu+CfhHM9slAOt883jfcnwXxHYi4PAt/6O52NrzWQhwjLcB17fjM9Dq73ug4muy/l/A\nrcF8D/dl6o1nBKOBNcaYdcaYGuBFILtJnWxgnm/5FeB46chTsfeBMWaLMeYb33IpsALr2c09STbw\njLF8CcSJSGoQ4jgeWGuM2ds7zTuNMeZTrGdq+PP/nM0DTm9m098A7xtjdhhjdgLvA536dPLmYjPG\n/NcYU+d7+SXWEwSDpoX3rz3a8/u+z1qLz/e342zghc4+blfpjYkgDcj1e53Hnn9oG+r4fhl2AYld\nEp0fX5PUKOCrZlYfKSLficg7IjKiSwOzHtP9XxFZJiLTmlnfnve4K0ym5V++YL5/9fYzxmzxLRcA\n+zVTpzu8lxdineE1p63PQqBN9zVfzW2haa07vH//B2w1xqxuYX2w38M29cZE0COISBTwKjDDGFPS\nZPU3WM0dBwOzgDe6OLxjjDGHACcBV4rIsV18/Db5Hn86AVjQzOpgv397MFYbQbe7VltEZgJ1wPMt\nVAnmZ+HfwCBgJLAFuqDgtgAAA6VJREFUq/mlO5pC62cD3f73qTcmgnwgw+91uq+s2Toi4gBigaIu\nic46phMrCTxvjHmt6XpjTIkxpsy3vAhwikhSV8VnjMn3zbcBr2Odfvtrz3scaCcB3xhjtjZdEez3\nz8/W+iYz33xbM3WC9l6KyAXAqcBvfYlqD+34LASMMWarMcZjjPECj7dw7KB+Fn1/P84EXmqpTjDf\nw/bqjYlgKTBERAb4vjVOBhY2qbMQqL86YxLwUUu/CJ3N1574JLDCGHNfC3X61PdZiMhorH+nLklU\nIhIpItH1y1idij82qbYQON939dARwC6/JpCu0uK3sGC+f034f86mAv9pps57wIkiEu9r+jjRVxZQ\nIjIe+CMwwRhT0UKd9nwWAhmjf7/TGS0cuz2/74H0a+AXY0xecyuD/R62W7B7qwMxYV3VsgrraoKZ\nvrLbsT70AG6sJoU1wNfAwC6M7RisJoLvgeW+6WTgMuAyX53pwE9YV0B8CRzVhfEN9B33O18M9e+f\nf3wCzPa9vz8AWV387xuJ9Yc91q8sqO8fVlLaAtRitVNfhNXv9CGwGvgASPDVzQKe8Nv2Qt9ncQ3w\n+y6KbQ1W23r9Z7D+Krq+wKLWPgtd+P496/t8fY/1xz21aYy+13v8vndFfL7yp+s/d351g/Ie7suk\nQ0wopVSI641NQ0oppTpAE4FSSoU4TQRKKRXiNBEopVSI00SglFIhThOBUk2IiKfJCKedNqKliGT6\nj2CpVHfgCHYASnVDlcaYkcEOQqmuomcESrWTb1z5e3xjy38tIoN95Zki8pFvcLQPRaSfr3w/31j/\n3/mmo3y7sovI42I9j+K/IhIetB9KKTQRKNWc8CZNQ+f4rdtljDkQeBh4wFc2C5hnjDkIa/C2h3zl\nDwGfGGvwu0Ow7iwFGALMNsaMAIqBiQH+eZRqld5ZrFQTIlJmjIlqpnwDcJwxZp1v4MACY0yiiGzH\nGv6g1le+xRiTJCKFQLoxptpvH5lYzx8Y4nt9I+A0xvwt8D+ZUs3TMwKlOsa0sNwR1X7LHrSvTgWZ\nJgKlOuYcv/n/fMtfYI16CfBb4DPf8ofA5QAiYheR2K4KUqmO0G8iSu0pvMmDyN81xtRfQhovIt9j\nfauf4iu7CnhKRG4ACoHf+8qvAeaIyEVY3/wvxxrBUqluRfsIlGonXx9BljFme7BjUaozadOQUkqF\nOD0jUEqpEKdnBEopFeI0ESilVIjTRKCUUiFOE4FSSoU4TQRKKRXi/h9JHz+UmKDsKAAAAABJRU5E\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiFYDx_58M76",
        "colab_type": "text"
      },
      "source": [
        "In addition, you should put up a (short) write-up following the [template](https://github.com/harvardnlp/cs6741/tree/master/nlp-template) provided in the repository. "
      ]
    }
  ]
}